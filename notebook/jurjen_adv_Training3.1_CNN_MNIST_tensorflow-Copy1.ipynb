{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCL6UCvWmggf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (default, Nov 22 2023, 10:22:35) \n",
      "[GCC 9.4.0]\n",
      "executable: \n",
      "/usr/bin/python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 22:36:10.966354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-12 22:36:11.154682: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-12 22:36:12.192400: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-12 22:36:12.192516: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-12 22:36:12.192521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "4.9.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(\"executable: \")\n",
    "print(sys.executable)\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow_datasets as tfds\n",
    "print(tfds.__version__)\n",
    "#print(\"TFDS version:\", tfds.__version__)\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "#import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "_dUJNbrZmggi",
    "outputId": "3802d63c-a895-4db8-ab3f-6d73da0341ea",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 22:36:22.301452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13232 MB memory:  -> device: 0, name: NVIDIA A16, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2025-01-12 22:36:22.303870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13232 MB memory:  -> device: 1, name: NVIDIA A16, pci bus id: 0000:1c:00.0, compute capability: 8.6\n",
      "2025-01-12 22:36:22.306071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 13232 MB memory:  -> device: 2, name: NVIDIA A16, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2025-01-12 22:36:22.308145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 13232 MB memory:  -> device: 3, name: NVIDIA A16, pci bus id: 0000:1e:00.0, compute capability: 8.6\n",
      "2025-01-12 22:36:22.310299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 13232 MB memory:  -> device: 4, name: NVIDIA A16, pci bus id: 0000:ce:00.0, compute capability: 8.6\n",
      "2025-01-12 22:36:22.312500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 13232 MB memory:  -> device: 5, name: NVIDIA A16, pci bus id: 0000:cf:00.0, compute capability: 8.6\n",
      "2025-01-12 22:36:22.315225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 13232 MB memory:  -> device: 6, name: NVIDIA A16, pci bus id: 0000:d0:00.0, compute capability: 8.6\n",
      "2025-01-12 22:36:22.317319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 13232 MB memory:  -> device: 7, name: NVIDIA A16, pci bus id: 0000:d1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#loading mnist data from tensorflow\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "#mnist = tfds.load(name='mnist', split='train', as_supervised=True)\n",
    "# Returns both train and test split separately\n",
    "mnist_train, mnist_test = tfds.load('mnist', split=['train', 'test'], as_supervised=True)\n",
    "def preprocess_image(image, label):\n",
    "    image = image\n",
    "    #image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1] # i believe this is not in the original code\n",
    "    label = tf.one_hot(label, depth=10)  # One-hot encode the label\n",
    "    return image, label\n",
    "mnist_train = mnist_train.map(preprocess_image)\n",
    "mnist_test = mnist_test.map(preprocess_image)\n",
    "mnist_train_atn = mnist_train.batch(100)\n",
    "mnist_test_atn = mnist_test.batch(100) #not used now since test is done in other code still"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "The following cells are regarding the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKt0nwHfmggn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#defining the network\n",
    "input_width = 28\n",
    "input_height = 28\n",
    "input_channels = 1\n",
    "input_pixels = 784\n",
    "\n",
    "n_conv1 = 32\n",
    "n_conv2 = 64\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 1\n",
    "conv1_k = 5\n",
    "conv2_k = 5\n",
    "max_pool1_k = 2\n",
    "max_pool2_k = 2\n",
    "\n",
    "n_hidden = 1024\n",
    "n_out = 10\n",
    "\n",
    "input_size_to_hidden = (input_width//(max_pool1_k*max_pool2_k)) * (input_height//(max_pool1_k*max_pool2_k)) *n_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "MYNlFqwTmggp",
    "outputId": "8cef8e57-c1cc-44d7-f067-d2f48268b393",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initialising the weights with random values\n",
    "# NOT USED IN THIS CODE WITH KERAS IMPLEMENTATION\n",
    "weights = {\n",
    "    \"wc1\" : tf.Variable(tf.random.normal([conv1_k, conv1_k, input_channels, n_conv1])),\n",
    "    \"wc2\" : tf.Variable(tf.random.normal([conv2_k, conv2_k, n_conv1, n_conv2])),\n",
    "    \"wh1\" : tf.Variable(tf.random.normal([input_size_to_hidden, n_hidden])),\n",
    "    \"wo\" : tf.Variable(tf.random.normal([n_hidden, n_out]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"bc1\" : tf.Variable(tf.random.normal([n_conv1])),\n",
    "    \"bc2\" : tf.Variable(tf.random.normal([n_conv2])),\n",
    "    \"bh1\" : tf.Variable(tf.random.normal([n_hidden])),\n",
    "    \"bo\" : tf.Variable(tf.random.normal([n_out])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psiAAeeymggr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions for layers\n",
    "def conv(x, weights, bias, strides = 1):\n",
    "    out = tf.nn.conv2d(x, weights, padding=\"SAME\", strides = [1, strides, strides, 1])\n",
    "    out = tf.nn.bias_add(out, bias)\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "\n",
    "def maxpooling(x, k = 2):\n",
    "    return tf.nn.max_pool(x, padding = \"SAME\", ksize = [1, k, k, 1], strides = [1, k, k, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktMBnG1ymggt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function for forward prop\n",
    "#This function is edited now with keras functionality. weights are now handled internally but can still be accessed with get_weights method\n",
    "def cnn(x):\n",
    "    # Define the layers using Keras API\n",
    "    #x = layers.Reshape((input_height, input_width, input_channels))(x)\n",
    "    \n",
    "    conv1 = layers.Conv2D(n_conv1, kernel_size=(conv1_k, conv1_k), strides=stride_conv1, padding=\"same\", activation=\"relu\")(x)\n",
    "    conv1_pool = layers.MaxPooling2D(pool_size=(max_pool1_k, max_pool1_k))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(n_conv2, kernel_size=(conv2_k, conv2_k), strides=stride_conv2, padding=\"same\", activation=\"relu\")(conv1_pool)\n",
    "    conv2_pool = layers.MaxPooling2D(pool_size=(max_pool2_k, max_pool2_k))(conv2)\n",
    "\n",
    "    # Flatten the output from convolutional layers\n",
    "    flatten = layers.Flatten()(conv2_pool)\n",
    "\n",
    "    # Fully connected layer\n",
    "    hidden = layers.Dense(n_hidden, activation=\"relu\")(flatten)\n",
    "\n",
    "    # Dropout\n",
    "    dropout = layers.Dropout(0.2)(hidden)\n",
    "\n",
    "    # Output layer (logits)\n",
    "    output = layers.Dense(n_out, activation = 'softmax')(dropout)\n",
    "    \n",
    "    return output\n",
    "    \n",
    "    #x = tf.reshape(x, shape = [-1 ,input_height, input_width, input_channels])\n",
    "    #conv1 = conv(x, weights['wc1'], biases['bc1'], stride_conv1)\n",
    "    #conv1_pool = maxpooling(conv1, max_pool1_k)\n",
    "    \n",
    "    #conv2 = conv(conv1_pool, weights['wc2'], biases['bc2'], stride_conv2)\n",
    "    #conv2_pool = maxpooling(conv2, max_pool2_k)\n",
    "    \n",
    "    #hidden_input = tf.reshape(conv2_pool, shape = [-1, input_size_to_hidden])\n",
    "    #hidden_output_before_activation = tf.add(tf.matmul(hidden_input, weights['wh1']), biases['bh1'])\n",
    "    #hidden_output_before_dropout = tf.nn.relu(hidden_output_before_activation)\n",
    "    #hidden_output = tf.nn.dropout(hidden_output_before_dropout, keep_prob) \n",
    "   \n",
    "    #output = tf.add(tf.matmul(hidden_output, weights['wo']), biases['bo']) #no softmax activation function since the loss function handles it already\n",
    "    #return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Nd0sB1XOmggv",
    "outputId": "e2817129-39a4-4317-aaf7-0043d729a2ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x = tf.keras.Input(shape=(input_pixels,))\n",
    "x = tf.keras.Input(shape=(input_height, input_width, input_channels))\n",
    "y = tf.keras.Input(shape=(n_out,))\n",
    "#pred is the model\n",
    "pred = cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKNqv-KZmgg0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.Model(inputs=[x], outputs=pred)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) #changed from 0.01 to 0.001\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "train_data = mnist_train #it will be given in batches by the create_partly_adv_data method\n",
    "test_data = mnist_test.batch(100)\n",
    "# Get a single batch from the test data (a batch is a tuple of (image, label))\n",
    "#single_batch = next(iter(test_data))\n",
    "\n",
    "# single_batch is a tuple, where single_batch[0] contains the image and single_batch[1] contains the label\n",
    "#image, label = single_batch\n",
    "\n",
    "# You can print or inspect the first image and label from the batch\n",
    "#print(image[0].numpy())  # The first image in the batch\n",
    "#print(label[0].numpy())  # The label for the first image\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following code is regarding the ATN and training the ATN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @ layers with 2 deconvolution layers\n",
    "def build_atn(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        # First convolutional layers to capture features\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),  # Downsample (14, 14, 64)\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),  # Downsample (7, 7, 128)\n",
    "\n",
    "        # Fully connected layer to integrate features\n",
    "        layers.Flatten(),  # Flatten to shape (7 * 7 * 128 = 6272)\n",
    "        layers.Dense(6272, activation='relu'),  # Match the reshape target\n",
    "\n",
    "        # Deconvolution layers to reconstruct adversarial examples\n",
    "        layers.Reshape((7, 7, 128)),  # Reshape for deconvolution\n",
    "        layers.Conv2DTranspose(128, (3, 3), activation='relu', strides=2, padding='same'),  # (14, 14, 128)\n",
    "        layers.Conv2DTranspose(64, (3, 3), activation='relu', strides=2, padding='same'),  # (28, 28, 64)\n",
    "        \n",
    "        layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same'),  # Output layer (28, 28, 1)\n",
    "        layers.Lambda(lambda x: x * 255)  # Scale to [0, 255]\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Build the ATN\n",
    "input_shape = (28, 28, 1)  # MNIST dataset shape\n",
    "atn = build_atn(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define input loss and output loss function\n",
    "def input_loss(x, x_prime):\n",
    "    return tf.reduce_mean(tf.square(tf.cast(x, tf.float32) - x_prime))  # Cast x to float32  # L2 loss\n",
    "\n",
    "def output_loss(y_pred, y_target):\n",
    "    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_target, y_pred)) # crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the models\n",
    "input_img = tf.keras.Input(shape=input_shape)\n",
    "x_prime = atn(input_img)\n",
    "y_pred = model(x_prime)\n",
    "\n",
    "combined_model = tf.keras.Model(inputs=input_img, outputs=[x_prime, y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_second_highest_target(y_pred_original):\n",
    "    # Sort predictions to find the highest and second-highest indices\n",
    "    top_2_indices = tf.argsort(y_pred_original, direction='DESCENDING', axis=1)[:, :2]\n",
    "    second_highest_indices = top_2_indices[:, 1]\n",
    "\n",
    "    # Create one-hot encoding for the second-highest class\n",
    "    y_target = tf.one_hot(second_highest_indices, depth=y_pred_original.shape[1])\n",
    "    return y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training procedure\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "beta = 0.1  # Weight for input-space loss\n",
    "\n",
    "@tf.function\n",
    "def atn_train_step(x, y_original):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Generate adversarial examples\n",
    "        x_prime = atn(x)\n",
    "\n",
    "        # Get predictions for original and adversarial inputs\n",
    "        y_pred_original = model(x, training=False)\n",
    "        y_pred = model(x_prime, training=False)\n",
    "\n",
    "        # Compute the second-highest target dynamically\n",
    "        y_target = get_second_highest_target(y_pred_original)\n",
    "\n",
    "        # Compute input loss and output loss separately\n",
    "        l_x = input_loss(x, x_prime)\n",
    "        l_y = output_loss(y_pred, y_target)\n",
    "\n",
    "        # Compute the combined loss\n",
    "        loss = beta * l_x + l_y\n",
    "\n",
    "    # Compute and apply gradients\n",
    "    gradients = tape.gradient(loss, atn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, atn.trainable_variables))\n",
    "\n",
    "    # Return total loss, input loss, and output loss\n",
    "    return loss, l_x, l_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def train_atn():\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 5 #for experiment reasons, changed from 50 to 5 now\n",
    "    batch_size = 32\n",
    "    beta = 0.01  # Weight for the input-space loss\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    print(f\"{'Epoch':<8}{'Total Loss':<12}{'Scaled Input Loss':<12}{'Output Loss':<12}{'Time (s)':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        epoch_loss = 0\n",
    "        epoch_input_loss = 0\n",
    "        epoch_output_loss = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        # Add progress bar for batches\n",
    "        for x_batch, y_original_batch in tqdm(mnist_train_atn, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "            loss, l_x, l_y = atn_train_step(x_batch, y_original_batch)  # Get all losses\n",
    "            epoch_loss += loss.numpy()\n",
    "            epoch_input_loss += l_x.numpy()*beta\n",
    "            epoch_output_loss += l_y.numpy()\n",
    "            batch_count += 1\n",
    "\n",
    "        # Compute average losses for the epoch\n",
    "        avg_loss = epoch_loss / batch_count\n",
    "        avg_input_loss = epoch_input_loss / batch_count\n",
    "        avg_output_loss = epoch_output_loss / batch_count\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"{epoch + 1:<8}{avg_loss:<12.4f}{avg_input_loss:<12.4f}{avg_output_loss:<12.4f}{elapsed_time:<10.2f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following code is regarding training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Added this cell for adversarial training\n",
    "#keras.config.enable_unsafe_deserialization()\n",
    "#atn = tf.keras.models.load_model('jurjen_adversarial_transformation_network_beta-0.01_epochs-50_conv2d_transpose.keras')\n",
    "\n",
    "def create_partly_adv_data(atn, dataset, indices):\n",
    "    mnist_train_images = np.array([x.numpy() for x, y in dataset])\n",
    "    mnist_train_labels = np.array([y.numpy() for x, y in dataset])\n",
    "    #random should ensure every epoch new images are used to generate adversarial samples\n",
    "    adversarial_samples = atn.predict(mnist_train_images[indices]) #get list of x prime's\n",
    "    print(f\"How many adversarial samples: {len(adversarial_samples)}\")\n",
    "    mnist_train_images[indices] = adversarial_samples\n",
    "    #recreate the tf.data.Dataset with the modified data\n",
    "    updated_mnist_train = tf.data.Dataset.from_tensor_slices((mnist_train_images, mnist_train_labels)).batch(100) #return it in batches of 100\n",
    "    return updated_mnist_train, adversarial_samples, mnist_train_labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cnn_train_step(batch_data, batch_labels, adversarial_samples, adversarial_labels, batchnumber):\n",
    "    global train_data_with_adv  # Allow modifications to train_data_with_adv\n",
    "    global train_data_iterator\n",
    "    # adv_true_labels is not a global variable since it is not changed, it just represents a subset of the train labels\n",
    "    \n",
    "    # Train the model on the current batch\n",
    "    model.train_on_batch(batch_data, batch_labels)\n",
    "    \n",
    "    # calculate accuracy on all adversarial examples of this epoch after each 50 batches\n",
    "    if ((batch_number + 1) % 50 == 0):\n",
    "         # Evaluate the model on all adversarial examples for the epoch\n",
    "        adv_preds_classes = np.argmax(model.predict(adversarial_samples), axis=1)\n",
    "        adv_true_classes = np.argmax(adversarial_labels, axis=1)\n",
    "        \n",
    "        # Compute accuracy on all adversarial examples\n",
    "        adv_accuracy = np.mean(adv_preds_classes == adv_true_classes) * 100\n",
    "        print(f\"Accuracy on all adversarial examples after batch {batchnumber + 1}: {adv_accuracy:.2f}%\")\n",
    "        if adv_accuracy > 50:\n",
    "            print(\"too high accuracy on adversarial samples, retraining atn\")\n",
    "            train_atn()\n",
    "            #replace the existing adversarial examples with new adversarial examples. \n",
    "            train_data_with_adv, adversarial_examples, adv_true_labels = create_partly_adv_data(atn, train_data, indices) #adv_true_labels here is not used outside this method as it is not changed by the method\n",
    "            train_data_iterator = iter(train_data_with_adv) #iterator is regenerated, initial one is assigned to old training data\n",
    "            for b in range(batch_number + 1):  # for the newly generated iterator skip up to the current batch number to continue where we left off.\n",
    "                next(train_data_iterator)\n",
    "            print(\"ATN retrained, adversarial examples and train_data_with_adv updated.\")\n",
    "\n",
    "            \n",
    "        #adv_indices = np.isin(batch_data.numpy(), adversarial_examples).nonzero()[0] #find the examples in the batch which are in the set adversarial examples \n",
    "        #if len(adv_indices) > 0:\n",
    "        #    adv_batch = batch_data.numpy()[adv_indices]\n",
    "        #    adv_batch_labels = adversarial_labels[adv_indices]\n",
    "        \n",
    "            # Get model predictions on adversarial samples\n",
    "            #adv_preds = model.predict(adv_batch) #perhaps later useful if wanna work with softmax outputs\n",
    "        #    adv_preds_classes = np.argmax((model.predict(adv_batch)), axis=1)\n",
    "        #    adv_true_classes = np.argmax(adv_batch_labels, axis=1)\n",
    "        \n",
    "            # Compute accuracy on adversarial examples\n",
    "        #    adv_accuracy = np.mean(adv_preds_classes == adv_true_classes) * 100\n",
    "        #    print(f\"Accuracy on adversarial examples in this batch: {adv_accuracy:.2f}%\")\n",
    "        #else:\n",
    "        #    print(\"No adversarial examples in this batch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/600 [00:00<?, ?it/s]2025-01-12 22:37:04.067089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8400\n",
      "2025-01-12 22:37:05.549789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Epoch 1/5: 100%|██████████| 600/600 [00:26<00:00, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       105.1939    10.0446     4.7480      26.24     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       27.4511     2.3098      4.3531      20.87     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       22.7614     1.8727      4.0346      20.81     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       20.5220     1.6687      3.8350      20.82     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       18.9583     1.5324      3.6345      20.79     \n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "batch : 1\n",
      "batch : 2\n",
      "batch : 3\n",
      "batch : 4\n",
      "batch : 5\n",
      "batch : 6\n",
      "batch : 7\n",
      "batch : 8\n",
      "batch : 9\n",
      "batch : 10\n",
      "batch : 11\n",
      "batch : 12\n",
      "batch : 13\n",
      "batch : 14\n",
      "batch : 15\n",
      "batch : 16\n",
      "batch : 17\n",
      "batch : 18\n",
      "batch : 19\n",
      "batch : 20\n",
      "batch : 21\n",
      "batch : 22\n",
      "batch : 23\n",
      "batch : 24\n",
      "batch : 25\n",
      "batch : 26\n",
      "batch : 27\n",
      "batch : 28\n",
      "batch : 29\n",
      "batch : 30\n",
      "batch : 31\n",
      "batch : 32\n",
      "batch : 33\n",
      "batch : 34\n",
      "batch : 35\n",
      "batch : 36\n",
      "batch : 37\n",
      "batch : 38\n",
      "batch : 39\n",
      "batch : 40\n",
      "batch : 41\n",
      "batch : 42\n",
      "batch : 43\n",
      "batch : 44\n",
      "batch : 45\n",
      "batch : 46\n",
      "batch : 47\n",
      "batch : 48\n",
      "batch : 49\n",
      "batch : 50\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 50: 91.11%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 29.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       18.3791     1.3305      5.0745      20.67     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:19<00:00, 30.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       16.7293     1.2038      4.6912      19.81     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       15.8650     1.1417      4.4481      20.45     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       15.4624     1.1156      4.3062      20.81     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       15.2332     1.1032      4.2010      20.83     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 51\n",
      "batch : 52\n",
      "batch : 53\n",
      "batch : 54\n",
      "batch : 55\n",
      "batch : 56\n",
      "batch : 57\n",
      "batch : 58\n",
      "batch : 59\n",
      "batch : 60\n",
      "batch : 61\n",
      "batch : 62\n",
      "batch : 63\n",
      "batch : 64\n",
      "batch : 65\n",
      "batch : 66\n",
      "batch : 67\n",
      "batch : 68\n",
      "batch : 69\n",
      "batch : 70\n",
      "batch : 71\n",
      "batch : 72\n",
      "batch : 73\n",
      "batch : 74\n",
      "batch : 75\n",
      "batch : 76\n",
      "batch : 77\n",
      "batch : 78\n",
      "batch : 79\n",
      "batch : 80\n",
      "batch : 81\n",
      "batch : 82\n",
      "batch : 83\n",
      "batch : 84\n",
      "batch : 85\n",
      "batch : 86\n",
      "batch : 87\n",
      "batch : 88\n",
      "batch : 89\n",
      "batch : 90\n",
      "batch : 91\n",
      "batch : 92\n",
      "batch : 93\n",
      "batch : 94\n",
      "batch : 95\n",
      "batch : 96\n",
      "batch : 97\n",
      "batch : 98\n",
      "batch : 99\n",
      "batch : 100\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 100: 95.30%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.3971     1.0813      5.5842      20.82     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 29.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       15.8707     1.0599      5.2721      20.67     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       15.2817     1.0230      5.0517      20.82     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       14.7423     0.9838      4.9039      20.73     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       14.6246     0.9828      4.7965      20.77     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 101\n",
      "batch : 102\n",
      "batch : 103\n",
      "batch : 104\n",
      "batch : 105\n",
      "batch : 106\n",
      "batch : 107\n",
      "batch : 108\n",
      "batch : 109\n",
      "batch : 110\n",
      "batch : 111\n",
      "batch : 112\n",
      "batch : 113\n",
      "batch : 114\n",
      "batch : 115\n",
      "batch : 116\n",
      "batch : 117\n",
      "batch : 118\n",
      "batch : 119\n",
      "batch : 120\n",
      "batch : 121\n",
      "batch : 122\n",
      "batch : 123\n",
      "batch : 124\n",
      "batch : 125\n",
      "batch : 126\n",
      "batch : 127\n",
      "batch : 128\n",
      "batch : 129\n",
      "batch : 130\n",
      "batch : 131\n",
      "batch : 132\n",
      "batch : 133\n",
      "batch : 134\n",
      "batch : 135\n",
      "batch : 136\n",
      "batch : 137\n",
      "batch : 138\n",
      "batch : 139\n",
      "batch : 140\n",
      "batch : 141\n",
      "batch : 142\n",
      "batch : 143\n",
      "batch : 144\n",
      "batch : 145\n",
      "batch : 146\n",
      "batch : 147\n",
      "batch : 148\n",
      "batch : 149\n",
      "batch : 150\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 150: 96.15%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.4094     0.9615      6.7939      20.87     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:19<00:00, 30.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       15.9309     0.9439      6.4918      19.99     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       15.7802     0.9459      6.3211      20.80     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       15.4938     0.9310      6.1838      20.85     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       15.3806     0.9308      6.0722      20.61     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 151\n",
      "batch : 152\n",
      "batch : 153\n",
      "batch : 154\n",
      "batch : 155\n",
      "batch : 156\n",
      "batch : 157\n",
      "batch : 158\n",
      "batch : 159\n",
      "batch : 160\n",
      "batch : 161\n",
      "batch : 162\n",
      "batch : 163\n",
      "batch : 164\n",
      "batch : 165\n",
      "batch : 166\n",
      "batch : 167\n",
      "batch : 168\n",
      "batch : 169\n",
      "batch : 170\n",
      "batch : 171\n",
      "batch : 172\n",
      "batch : 173\n",
      "batch : 174\n",
      "batch : 175\n",
      "batch : 176\n",
      "batch : 177\n",
      "batch : 178\n",
      "batch : 179\n",
      "batch : 180\n",
      "batch : 181\n",
      "batch : 182\n",
      "batch : 183\n",
      "batch : 184\n",
      "batch : 185\n",
      "batch : 186\n",
      "batch : 187\n",
      "batch : 188\n",
      "batch : 189\n",
      "batch : 190\n",
      "batch : 191\n",
      "batch : 192\n",
      "batch : 193\n",
      "batch : 194\n",
      "batch : 195\n",
      "batch : 196\n",
      "batch : 197\n",
      "batch : 198\n",
      "batch : 199\n",
      "batch : 200\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 200: 97.18%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       17.1207     0.9393      7.7273      20.90     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       16.4821     0.9316      7.1665      20.89     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       16.0751     0.9193      6.8822      20.92     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       15.9316     0.9256      6.6755      20.89     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       15.9365     0.9419      6.5174      20.89     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 201\n",
      "batch : 202\n",
      "batch : 203\n",
      "batch : 204\n",
      "batch : 205\n",
      "batch : 206\n",
      "batch : 207\n",
      "batch : 208\n",
      "batch : 209\n",
      "batch : 210\n",
      "batch : 211\n",
      "batch : 212\n",
      "batch : 213\n",
      "batch : 214\n",
      "batch : 215\n",
      "batch : 216\n",
      "batch : 217\n",
      "batch : 218\n",
      "batch : 219\n",
      "batch : 220\n",
      "batch : 221\n",
      "batch : 222\n",
      "batch : 223\n",
      "batch : 224\n",
      "batch : 225\n",
      "batch : 226\n",
      "batch : 227\n",
      "batch : 228\n",
      "batch : 229\n",
      "batch : 230\n",
      "batch : 231\n",
      "batch : 232\n",
      "batch : 233\n",
      "batch : 234\n",
      "batch : 235\n",
      "batch : 236\n",
      "batch : 237\n",
      "batch : 238\n",
      "batch : 239\n",
      "batch : 240\n",
      "batch : 241\n",
      "batch : 242\n",
      "batch : 243\n",
      "batch : 244\n",
      "batch : 245\n",
      "batch : 246\n",
      "batch : 247\n",
      "batch : 248\n",
      "batch : 249\n",
      "batch : 250\n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "Accuracy on all adversarial examples after batch 250: 97.36%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.0630     0.8863      7.2000      20.76     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       15.2951     0.8407      6.8880      20.75     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       14.5121     0.7820      6.6918      20.88     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 29.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       14.1620     0.7602      6.5601      20.15     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 29.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       14.0218     0.7563      6.4589      20.40     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 251\n",
      "batch : 252\n",
      "batch : 253\n",
      "batch : 254\n",
      "batch : 255\n",
      "batch : 256\n",
      "batch : 257\n",
      "batch : 258\n",
      "batch : 259\n",
      "batch : 260\n",
      "batch : 261\n",
      "batch : 262\n",
      "batch : 263\n",
      "batch : 264\n",
      "batch : 265\n",
      "batch : 266\n",
      "batch : 267\n",
      "batch : 268\n",
      "batch : 269\n",
      "batch : 270\n",
      "batch : 271\n",
      "batch : 272\n",
      "batch : 273\n",
      "batch : 274\n",
      "batch : 275\n",
      "batch : 276\n",
      "batch : 277\n",
      "batch : 278\n",
      "batch : 279\n",
      "batch : 280\n",
      "batch : 281\n",
      "batch : 282\n",
      "batch : 283\n",
      "batch : 284\n",
      "batch : 285\n",
      "batch : 286\n",
      "batch : 287\n",
      "batch : 288\n",
      "batch : 289\n",
      "batch : 290\n",
      "batch : 291\n",
      "batch : 292\n",
      "batch : 293\n",
      "batch : 294\n",
      "batch : 295\n",
      "batch : 296\n",
      "batch : 297\n",
      "batch : 298\n",
      "batch : 299\n",
      "batch : 300\n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "Accuracy on all adversarial examples after batch 300: 97.57%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       15.5636     0.7987      7.5764      20.90     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       15.4100     0.8223      7.1869      20.90     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       15.3528     0.8340      7.0129      20.84     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       15.2514     0.8370      6.8816      20.85     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       15.1862     0.8410      6.7765      20.81     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 301\n",
      "batch : 302\n",
      "batch : 303\n",
      "batch : 304\n",
      "batch : 305\n",
      "batch : 306\n",
      "batch : 307\n",
      "batch : 308\n",
      "batch : 309\n",
      "batch : 310\n",
      "batch : 311\n",
      "batch : 312\n",
      "batch : 313\n",
      "batch : 314\n",
      "batch : 315\n",
      "batch : 316\n",
      "batch : 317\n",
      "batch : 318\n",
      "batch : 319\n",
      "batch : 320\n",
      "batch : 321\n",
      "batch : 322\n",
      "batch : 323\n",
      "batch : 324\n",
      "batch : 325\n",
      "batch : 326\n",
      "batch : 327\n",
      "batch : 328\n",
      "batch : 329\n",
      "batch : 330\n",
      "batch : 331\n",
      "batch : 332\n",
      "batch : 333\n",
      "batch : 334\n",
      "batch : 335\n",
      "batch : 336\n",
      "batch : 337\n",
      "batch : 338\n",
      "batch : 339\n",
      "batch : 340\n",
      "batch : 341\n",
      "batch : 342\n",
      "batch : 343\n",
      "batch : 344\n",
      "batch : 345\n",
      "batch : 346\n",
      "batch : 347\n",
      "batch : 348\n",
      "batch : 349\n",
      "batch : 350\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 350: 97.90%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.2586     0.8076      8.1825      20.86     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       15.9922     0.8113      7.8791      20.90     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       15.9786     0.8240      7.7383      20.79     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       15.9378     0.8305      7.6325      20.87     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       15.9813     0.8428      7.5528      20.89     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 351\n",
      "batch : 352\n",
      "batch : 353\n",
      "batch : 354\n",
      "batch : 355\n",
      "batch : 356\n",
      "batch : 357\n",
      "batch : 358\n",
      "batch : 359\n",
      "batch : 360\n",
      "batch : 361\n",
      "batch : 362\n",
      "batch : 363\n",
      "batch : 364\n",
      "batch : 365\n",
      "batch : 366\n",
      "batch : 367\n",
      "batch : 368\n",
      "batch : 369\n",
      "batch : 370\n",
      "batch : 371\n",
      "batch : 372\n",
      "batch : 373\n",
      "batch : 374\n",
      "batch : 375\n",
      "batch : 376\n",
      "batch : 377\n",
      "batch : 378\n",
      "batch : 379\n",
      "batch : 380\n",
      "batch : 381\n",
      "batch : 382\n",
      "batch : 383\n",
      "batch : 384\n",
      "batch : 385\n",
      "batch : 386\n",
      "batch : 387\n",
      "batch : 388\n",
      "batch : 389\n",
      "batch : 390\n",
      "batch : 391\n",
      "batch : 392\n",
      "batch : 393\n",
      "batch : 394\n",
      "batch : 395\n",
      "batch : 396\n",
      "batch : 397\n",
      "batch : 398\n",
      "batch : 399\n",
      "batch : 400\n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "Accuracy on all adversarial examples after batch 400: 97.81%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.1912     0.8388      7.8028      20.84     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       15.7090     0.8234      7.4747      20.84     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       15.3818     0.8077      7.3043      20.84     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       15.3036     0.8127      7.1770      20.76     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       15.4376     0.8347      7.0905      20.82     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 401\n",
      "batch : 402\n",
      "batch : 403\n",
      "batch : 404\n",
      "batch : 405\n",
      "batch : 406\n",
      "batch : 407\n",
      "batch : 408\n",
      "batch : 409\n",
      "batch : 410\n",
      "batch : 411\n",
      "batch : 412\n",
      "batch : 413\n",
      "batch : 414\n",
      "batch : 415\n",
      "batch : 416\n",
      "batch : 417\n",
      "batch : 418\n",
      "batch : 419\n",
      "batch : 420\n",
      "batch : 421\n",
      "batch : 422\n",
      "batch : 423\n",
      "batch : 424\n",
      "batch : 425\n",
      "batch : 426\n",
      "batch : 427\n",
      "batch : 428\n",
      "batch : 429\n",
      "batch : 430\n",
      "batch : 431\n",
      "batch : 432\n",
      "batch : 433\n",
      "batch : 434\n",
      "batch : 435\n",
      "batch : 436\n",
      "batch : 437\n",
      "batch : 438\n",
      "batch : 439\n",
      "batch : 440\n",
      "batch : 441\n",
      "batch : 442\n",
      "batch : 443\n",
      "batch : 444\n",
      "batch : 445\n",
      "batch : 446\n",
      "batch : 447\n",
      "batch : 448\n",
      "batch : 449\n",
      "batch : 450\n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "Accuracy on all adversarial examples after batch 450: 97.81%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       15.9700     0.7829      8.1413      20.75     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       15.0635     0.7235      7.8288      20.82     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       14.4538     0.6802      7.6516      20.88     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       14.1957     0.6671      7.5251      20.61     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       14.0935     0.6665      7.4284      20.81     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 451\n",
      "batch : 452\n",
      "batch : 453\n",
      "batch : 454\n",
      "batch : 455\n",
      "batch : 456\n",
      "batch : 457\n",
      "batch : 458\n",
      "batch : 459\n",
      "batch : 460\n",
      "batch : 461\n",
      "batch : 462\n",
      "batch : 463\n",
      "batch : 464\n",
      "batch : 465\n",
      "batch : 466\n",
      "batch : 467\n",
      "batch : 468\n",
      "batch : 469\n",
      "batch : 470\n",
      "batch : 471\n",
      "batch : 472\n",
      "batch : 473\n",
      "batch : 474\n",
      "batch : 475\n",
      "batch : 476\n",
      "batch : 477\n",
      "batch : 478\n",
      "batch : 479\n",
      "batch : 480\n",
      "batch : 481\n",
      "batch : 482\n",
      "batch : 483\n",
      "batch : 484\n",
      "batch : 485\n",
      "batch : 486\n",
      "batch : 487\n",
      "batch : 488\n",
      "batch : 489\n",
      "batch : 490\n",
      "batch : 491\n",
      "batch : 492\n",
      "batch : 493\n",
      "batch : 494\n",
      "batch : 495\n",
      "batch : 496\n",
      "batch : 497\n",
      "batch : 498\n",
      "batch : 499\n",
      "batch : 500\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 500: 98.28%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.4328     0.6995      9.4374      20.85     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 29.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       16.3492     0.7247      9.1018      20.06     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 29.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       16.3097     0.7367      8.9423      20.40     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       16.2909     0.7455      8.8357      20.82     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       16.2930     0.7545      8.7482      20.70     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 501\n",
      "batch : 502\n",
      "batch : 503\n",
      "batch : 504\n",
      "batch : 505\n",
      "batch : 506\n",
      "batch : 507\n",
      "batch : 508\n",
      "batch : 509\n",
      "batch : 510\n",
      "batch : 511\n",
      "batch : 512\n",
      "batch : 513\n",
      "batch : 514\n",
      "batch : 515\n",
      "batch : 516\n",
      "batch : 517\n",
      "batch : 518\n",
      "batch : 519\n",
      "batch : 520\n",
      "batch : 521\n",
      "batch : 522\n",
      "batch : 523\n",
      "batch : 524\n",
      "batch : 525\n",
      "batch : 526\n",
      "batch : 527\n",
      "batch : 528\n",
      "batch : 529\n",
      "batch : 530\n",
      "batch : 531\n",
      "batch : 532\n",
      "batch : 533\n",
      "batch : 534\n",
      "batch : 535\n",
      "batch : 536\n",
      "batch : 537\n",
      "batch : 538\n",
      "batch : 539\n",
      "batch : 540\n",
      "batch : 541\n",
      "batch : 542\n",
      "batch : 543\n",
      "batch : 544\n",
      "batch : 545\n",
      "batch : 546\n",
      "batch : 547\n",
      "batch : 548\n",
      "batch : 549\n",
      "batch : 550\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 550: 98.24%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       15.9405     0.7200      8.7400      20.79     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       15.7210     0.7203      8.5180      20.87     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       15.7565     0.7352      8.4044      20.85     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       15.9621     0.7626      8.3363      20.61     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       16.0631     0.7794      8.2688      20.86     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 551\n",
      "batch : 552\n",
      "batch : 553\n",
      "batch : 554\n",
      "batch : 555\n",
      "batch : 556\n",
      "batch : 557\n",
      "batch : 558\n",
      "batch : 559\n",
      "batch : 560\n",
      "batch : 561\n",
      "batch : 562\n",
      "batch : 563\n",
      "batch : 564\n",
      "batch : 565\n",
      "batch : 566\n",
      "batch : 567\n",
      "batch : 568\n",
      "batch : 569\n",
      "batch : 570\n",
      "batch : 571\n",
      "batch : 572\n",
      "batch : 573\n",
      "batch : 574\n",
      "batch : 575\n",
      "batch : 576\n",
      "batch : 577\n",
      "batch : 578\n",
      "batch : 579\n",
      "batch : 580\n",
      "batch : 581\n",
      "batch : 582\n",
      "batch : 583\n",
      "batch : 584\n",
      "batch : 585\n",
      "batch : 586\n",
      "batch : 587\n",
      "batch : 588\n",
      "batch : 589\n",
      "batch : 590\n",
      "batch : 591\n",
      "batch : 592\n",
      "batch : 593\n",
      "batch : 594\n",
      "batch : 595\n",
      "batch : 596\n",
      "batch : 597\n",
      "batch : 598\n",
      "batch : 599\n",
      "batch : 600\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 600: 98.33%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.6233     0.7713      8.9107      20.87     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       16.4857     0.7827      8.6588      20.83     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       16.6029     0.8055      8.5481      20.94     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       16.4944     0.8036      8.4586      20.77     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       16.0786     0.7724      8.3548      20.89     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "Target model accuracy on adversarial samples for epoch 1: 98.33%\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "batch : 1\n",
      "batch : 2\n",
      "batch : 3\n",
      "batch : 4\n",
      "batch : 5\n",
      "batch : 6\n",
      "batch : 7\n",
      "batch : 8\n",
      "batch : 9\n",
      "batch : 10\n",
      "batch : 11\n",
      "batch : 12\n",
      "batch : 13\n",
      "batch : 14\n",
      "batch : 15\n",
      "batch : 16\n",
      "batch : 17\n",
      "batch : 18\n",
      "batch : 19\n",
      "batch : 20\n",
      "batch : 21\n",
      "batch : 22\n",
      "batch : 23\n",
      "batch : 24\n",
      "batch : 25\n",
      "batch : 26\n",
      "batch : 27\n",
      "batch : 28\n",
      "batch : 29\n",
      "batch : 30\n",
      "batch : 31\n",
      "batch : 32\n",
      "batch : 33\n",
      "batch : 34\n",
      "batch : 35\n",
      "batch : 36\n",
      "batch : 37\n",
      "batch : 38\n",
      "batch : 39\n",
      "batch : 40\n",
      "batch : 41\n",
      "batch : 42\n",
      "batch : 43\n",
      "batch : 44\n",
      "batch : 45\n",
      "batch : 46\n",
      "batch : 47\n",
      "batch : 48\n",
      "batch : 49\n",
      "batch : 50\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 50: 96.94%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 29.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       15.0556     0.6756      8.2992      20.57     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       14.3172     0.6276      8.0411      20.80     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       14.0306     0.6134      7.8970      20.78     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       13.9132     0.6119      7.7940      20.73     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       13.9061     0.6191      7.7147      20.84     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 51\n",
      "batch : 52\n",
      "batch : 53\n",
      "batch : 54\n",
      "batch : 55\n",
      "batch : 56\n",
      "batch : 57\n",
      "batch : 58\n",
      "batch : 59\n",
      "batch : 60\n",
      "batch : 61\n",
      "batch : 62\n",
      "batch : 63\n",
      "batch : 64\n",
      "batch : 65\n",
      "batch : 66\n",
      "batch : 67\n",
      "batch : 68\n",
      "batch : 69\n",
      "batch : 70\n",
      "batch : 71\n",
      "batch : 72\n",
      "batch : 73\n",
      "batch : 74\n",
      "batch : 75\n",
      "batch : 76\n",
      "batch : 77\n",
      "batch : 78\n",
      "batch : 79\n",
      "batch : 80\n",
      "batch : 81\n",
      "batch : 82\n",
      "batch : 83\n",
      "batch : 84\n",
      "batch : 85\n",
      "batch : 86\n",
      "batch : 87\n",
      "batch : 88\n",
      "batch : 89\n",
      "batch : 90\n",
      "batch : 91\n",
      "batch : 92\n",
      "batch : 93\n",
      "batch : 94\n",
      "batch : 95\n",
      "batch : 96\n",
      "batch : 97\n",
      "batch : 98\n",
      "batch : 99\n",
      "batch : 100\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 100: 98.30%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       15.5509     0.6525      9.0255      20.84     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       15.4384     0.6638      8.8005      20.80     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 29.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       15.3803     0.6690      8.6905      20.54     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 29.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       15.3412     0.6744      8.5975      20.62     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 29.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       15.3361     0.6807      8.5286      20.66     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 101\n",
      "batch : 102\n",
      "batch : 103\n",
      "batch : 104\n",
      "batch : 105\n",
      "batch : 106\n",
      "batch : 107\n",
      "batch : 108\n",
      "batch : 109\n",
      "batch : 110\n",
      "batch : 111\n",
      "batch : 112\n",
      "batch : 113\n",
      "batch : 114\n",
      "batch : 115\n",
      "batch : 116\n",
      "batch : 117\n",
      "batch : 118\n",
      "batch : 119\n",
      "batch : 120\n",
      "batch : 121\n",
      "batch : 122\n",
      "batch : 123\n",
      "batch : 124\n",
      "batch : 125\n",
      "batch : 126\n",
      "batch : 127\n",
      "batch : 128\n",
      "batch : 129\n",
      "batch : 130\n",
      "batch : 131\n",
      "batch : 132\n",
      "batch : 133\n",
      "batch : 134\n",
      "batch : 135\n",
      "batch : 136\n",
      "batch : 137\n",
      "batch : 138\n",
      "batch : 139\n",
      "batch : 140\n",
      "batch : 141\n",
      "batch : 142\n",
      "batch : 143\n",
      "batch : 144\n",
      "batch : 145\n",
      "batch : 146\n",
      "batch : 147\n",
      "batch : 148\n",
      "batch : 149\n",
      "batch : 150\n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "Accuracy on all adversarial examples after batch 150: 98.24%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 29.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       15.9297     0.6870      9.0596      20.66     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       15.8307     0.6966      8.8643      20.84     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       15.7352     0.6986      8.7490      20.83     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       15.8294     0.7140      8.6890      20.82     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       16.0054     0.7362      8.6438      20.81     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 151\n",
      "batch : 152\n",
      "batch : 153\n",
      "batch : 154\n",
      "batch : 155\n",
      "batch : 156\n",
      "batch : 157\n",
      "batch : 158\n",
      "batch : 159\n",
      "batch : 160\n",
      "batch : 161\n",
      "batch : 162\n",
      "batch : 163\n",
      "batch : 164\n",
      "batch : 165\n",
      "batch : 166\n",
      "batch : 167\n",
      "batch : 168\n",
      "batch : 169\n",
      "batch : 170\n",
      "batch : 171\n",
      "batch : 172\n",
      "batch : 173\n",
      "batch : 174\n",
      "batch : 175\n",
      "batch : 176\n",
      "batch : 177\n",
      "batch : 178\n",
      "batch : 179\n",
      "batch : 180\n",
      "batch : 181\n",
      "batch : 182\n",
      "batch : 183\n",
      "batch : 184\n",
      "batch : 185\n",
      "batch : 186\n",
      "batch : 187\n",
      "batch : 188\n",
      "batch : 189\n",
      "batch : 190\n",
      "batch : 191\n",
      "batch : 192\n",
      "batch : 193\n",
      "batch : 194\n",
      "batch : 195\n",
      "batch : 196\n",
      "batch : 197\n",
      "batch : 198\n",
      "batch : 199\n",
      "batch : 200\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 200: 97.82%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       17.8844     0.7661      10.2234     20.80     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       17.5246     0.7740      9.7843      20.81     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       17.7017     0.8082      9.6201      20.84     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       17.9364     0.8416      9.5202      20.79     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       17.8463     0.8420      9.4267      20.81     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 201\n",
      "batch : 202\n",
      "batch : 203\n",
      "batch : 204\n",
      "batch : 205\n",
      "batch : 206\n",
      "batch : 207\n",
      "batch : 208\n",
      "batch : 209\n",
      "batch : 210\n",
      "batch : 211\n",
      "batch : 212\n",
      "batch : 213\n",
      "batch : 214\n",
      "batch : 215\n",
      "batch : 216\n",
      "batch : 217\n",
      "batch : 218\n",
      "batch : 219\n",
      "batch : 220\n",
      "batch : 221\n",
      "batch : 222\n",
      "batch : 223\n",
      "batch : 224\n",
      "batch : 225\n",
      "batch : 226\n",
      "batch : 227\n",
      "batch : 228\n",
      "batch : 229\n",
      "batch : 230\n",
      "batch : 231\n",
      "batch : 232\n",
      "batch : 233\n",
      "batch : 234\n",
      "batch : 235\n",
      "batch : 236\n",
      "batch : 237\n",
      "batch : 238\n",
      "batch : 239\n",
      "batch : 240\n",
      "batch : 241\n",
      "batch : 242\n",
      "batch : 243\n",
      "batch : 244\n",
      "batch : 245\n",
      "batch : 246\n",
      "batch : 247\n",
      "batch : 248\n",
      "batch : 249\n",
      "batch : 250\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 250: 97.96%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.6443     0.7423      9.2217      20.87     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       15.4178     0.6625      8.7930      20.85     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       14.9033     0.6327      8.5767      20.93     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       14.6929     0.6264      8.4294      20.90     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       14.6151     0.6296      8.3190      20.88     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 251\n",
      "batch : 252\n",
      "batch : 253\n",
      "batch : 254\n",
      "batch : 255\n",
      "batch : 256\n",
      "batch : 257\n",
      "batch : 258\n",
      "batch : 259\n",
      "batch : 260\n",
      "batch : 261\n",
      "batch : 262\n",
      "batch : 263\n",
      "batch : 264\n",
      "batch : 265\n",
      "batch : 266\n",
      "batch : 267\n",
      "batch : 268\n",
      "batch : 269\n",
      "batch : 270\n",
      "batch : 271\n",
      "batch : 272\n",
      "batch : 273\n",
      "batch : 274\n",
      "batch : 275\n",
      "batch : 276\n",
      "batch : 277\n",
      "batch : 278\n",
      "batch : 279\n",
      "batch : 280\n",
      "batch : 281\n",
      "batch : 282\n",
      "batch : 283\n",
      "batch : 284\n",
      "batch : 285\n",
      "batch : 286\n",
      "batch : 287\n",
      "batch : 288\n",
      "batch : 289\n",
      "batch : 290\n",
      "batch : 291\n",
      "batch : 292\n",
      "batch : 293\n",
      "batch : 294\n",
      "batch : 295\n",
      "batch : 296\n",
      "batch : 297\n",
      "batch : 298\n",
      "batch : 299\n",
      "batch : 300\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 300: 97.92%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.2480     0.6575      9.6730      20.82     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       16.0357     0.6754      9.2813      20.84     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       16.0114     0.6915      9.0965      20.70     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       15.9058     0.6951      8.9547      20.79     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       15.8724     0.7031      8.8412      20.77     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 301\n",
      "batch : 302\n",
      "batch : 303\n",
      "batch : 304\n",
      "batch : 305\n",
      "batch : 306\n",
      "batch : 307\n",
      "batch : 308\n",
      "batch : 309\n",
      "batch : 310\n",
      "batch : 311\n",
      "batch : 312\n",
      "batch : 313\n",
      "batch : 314\n",
      "batch : 315\n",
      "batch : 316\n",
      "batch : 317\n",
      "batch : 318\n",
      "batch : 319\n",
      "batch : 320\n",
      "batch : 321\n",
      "batch : 322\n",
      "batch : 323\n",
      "batch : 324\n",
      "batch : 325\n",
      "batch : 326\n",
      "batch : 327\n",
      "batch : 328\n",
      "batch : 329\n",
      "batch : 330\n",
      "batch : 331\n",
      "batch : 332\n",
      "batch : 333\n",
      "batch : 334\n",
      "batch : 335\n",
      "batch : 336\n",
      "batch : 337\n",
      "batch : 338\n",
      "batch : 339\n",
      "batch : 340\n",
      "batch : 341\n",
      "batch : 342\n",
      "batch : 343\n",
      "batch : 344\n",
      "batch : 345\n",
      "batch : 346\n",
      "batch : 347\n",
      "batch : 348\n",
      "batch : 349\n",
      "batch : 350\n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "Accuracy on all adversarial examples after batch 350: 98.55%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.6417     0.6909      9.7322      20.83     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       16.3821     0.6947      9.4352      20.84     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       16.3720     0.7076      9.2964      20.75     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 29.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       16.2972     0.7106      9.1915      20.36     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       16.2642     0.7156      9.1078      20.78     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 351\n",
      "batch : 352\n",
      "batch : 353\n",
      "batch : 354\n",
      "batch : 355\n",
      "batch : 356\n",
      "batch : 357\n",
      "batch : 358\n",
      "batch : 359\n",
      "batch : 360\n",
      "batch : 361\n",
      "batch : 362\n",
      "batch : 363\n",
      "batch : 364\n",
      "batch : 365\n",
      "batch : 366\n",
      "batch : 367\n",
      "batch : 368\n",
      "batch : 369\n",
      "batch : 370\n",
      "batch : 371\n",
      "batch : 372\n",
      "batch : 373\n",
      "batch : 374\n",
      "batch : 375\n",
      "batch : 376\n",
      "batch : 377\n",
      "batch : 378\n",
      "batch : 379\n",
      "batch : 380\n",
      "batch : 381\n",
      "batch : 382\n",
      "batch : 383\n",
      "batch : 384\n",
      "batch : 385\n",
      "batch : 386\n",
      "batch : 387\n",
      "batch : 388\n",
      "batch : 389\n",
      "batch : 390\n",
      "batch : 391\n",
      "batch : 392\n",
      "batch : 393\n",
      "batch : 394\n",
      "batch : 395\n",
      "batch : 396\n",
      "batch : 397\n",
      "batch : 398\n",
      "batch : 399\n",
      "batch : 400\n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "Accuracy on all adversarial examples after batch 400: 97.76%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.8425     0.7013      9.8297      20.89     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       16.7251     0.7173      9.5523      20.95     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       16.8959     0.7453      9.4434      20.87     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       16.8104     0.7465      9.3453      20.84     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 28.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       16.9134     0.7637      9.2761      20.83     \n",
      "938/938 [==============================] - 5s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 401\n",
      "batch : 402\n",
      "batch : 403\n",
      "batch : 404\n",
      "batch : 405\n",
      "batch : 406\n",
      "batch : 407\n",
      "batch : 408\n",
      "batch : 409\n",
      "batch : 410\n",
      "batch : 411\n",
      "batch : 412\n",
      "batch : 413\n",
      "batch : 414\n",
      "batch : 415\n",
      "batch : 416\n",
      "batch : 417\n",
      "batch : 418\n",
      "batch : 419\n",
      "batch : 420\n",
      "batch : 421\n",
      "batch : 422\n",
      "batch : 423\n",
      "batch : 424\n",
      "batch : 425\n",
      "batch : 426\n",
      "batch : 427\n",
      "batch : 428\n",
      "batch : 429\n",
      "batch : 430\n",
      "batch : 431\n",
      "batch : 432\n",
      "batch : 433\n",
      "batch : 434\n",
      "batch : 435\n",
      "batch : 436\n",
      "batch : 437\n",
      "batch : 438\n",
      "batch : 439\n",
      "batch : 440\n",
      "batch : 441\n",
      "batch : 442\n",
      "batch : 443\n",
      "batch : 444\n",
      "batch : 445\n",
      "batch : 446\n",
      "batch : 447\n",
      "batch : 448\n",
      "batch : 449\n",
      "batch : 450\n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "Accuracy on all adversarial examples after batch 450: 98.48%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 28.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       17.0048     0.7690      9.3150      20.84     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       16.5348     0.7522      9.0126      20.87     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 28.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       16.4048     0.7539      8.8654      20.86     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 29.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       16.7194     0.7915      8.8046      20.04     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 29.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       16.7620     0.8019      8.7428      20.22     \n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 451\n",
      "batch : 452\n",
      "batch : 453\n",
      "batch : 454\n",
      "batch : 455\n",
      "batch : 456\n",
      "batch : 457\n",
      "batch : 458\n",
      "batch : 459\n",
      "batch : 460\n",
      "batch : 461\n",
      "batch : 462\n",
      "batch : 463\n",
      "batch : 464\n",
      "batch : 465\n",
      "batch : 466\n",
      "batch : 467\n",
      "batch : 468\n",
      "batch : 469\n",
      "batch : 470\n",
      "batch : 471\n",
      "batch : 472\n",
      "batch : 473\n",
      "batch : 474\n",
      "batch : 475\n",
      "batch : 476\n",
      "batch : 477\n",
      "batch : 478\n",
      "batch : 479\n",
      "batch : 480\n",
      "batch : 481\n",
      "batch : 482\n",
      "batch : 483\n",
      "batch : 484\n",
      "batch : 485\n",
      "batch : 486\n",
      "batch : 487\n",
      "batch : 488\n",
      "batch : 489\n",
      "batch : 490\n",
      "batch : 491\n",
      "batch : 492\n",
      "batch : 493\n",
      "batch : 494\n",
      "batch : 495\n",
      "batch : 496\n",
      "batch : 497\n",
      "batch : 498\n",
      "batch : 499\n",
      "batch : 500\n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "Accuracy on all adversarial examples after batch 500: 98.23%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 29.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       17.3885     0.7148      10.2408     20.14     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 29.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       16.2243     0.6500      9.7242      20.17     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 29.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       15.7758     0.6357      9.4189      20.26     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       15.5788     0.6349      9.2299      20.61     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 29.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       15.5028     0.6407      9.0961      20.31     \n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 501\n",
      "batch : 502\n",
      "batch : 503\n",
      "batch : 504\n",
      "batch : 505\n",
      "batch : 506\n",
      "batch : 507\n",
      "batch : 508\n",
      "batch : 509\n",
      "batch : 510\n",
      "batch : 511\n",
      "batch : 512\n",
      "batch : 513\n",
      "batch : 514\n",
      "batch : 515\n",
      "batch : 516\n",
      "batch : 517\n",
      "batch : 518\n",
      "batch : 519\n",
      "batch : 520\n",
      "batch : 521\n",
      "batch : 522\n",
      "batch : 523\n",
      "batch : 524\n",
      "batch : 525\n",
      "batch : 526\n",
      "batch : 527\n",
      "batch : 528\n",
      "batch : 529\n",
      "batch : 530\n",
      "batch : 531\n",
      "batch : 532\n",
      "batch : 533\n",
      "batch : 534\n",
      "batch : 535\n",
      "batch : 536\n",
      "batch : 537\n",
      "batch : 538\n",
      "batch : 539\n",
      "batch : 540\n",
      "batch : 541\n",
      "batch : 542\n",
      "batch : 543\n",
      "batch : 544\n",
      "batch : 545\n",
      "batch : 546\n",
      "batch : 547\n",
      "batch : 548\n",
      "batch : 549\n",
      "batch : 550\n",
      "938/938 [==============================] - 3s 4ms/step\n",
      "Accuracy on all adversarial examples after batch 550: 98.16%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       17.5093     0.6474      11.0348     20.27     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 29.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       17.2128     0.6655      10.5575     20.22     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 29.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       17.0897     0.6739      10.3503     20.21     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 29.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       17.0498     0.6844      10.2054     20.21     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:20<00:00, 29.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       17.0569     0.6956      10.1010     20.22     \n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "batch : 551\n",
      "batch : 552\n",
      "batch : 553\n",
      "batch : 554\n",
      "batch : 555\n",
      "batch : 556\n",
      "batch : 557\n",
      "batch : 558\n",
      "batch : 559\n",
      "batch : 560\n",
      "batch : 561\n",
      "batch : 562\n",
      "batch : 563\n",
      "batch : 564\n",
      "batch : 565\n",
      "batch : 566\n",
      "batch : 567\n",
      "batch : 568\n",
      "batch : 569\n",
      "batch : 570\n",
      "batch : 571\n",
      "batch : 572\n",
      "batch : 573\n",
      "batch : 574\n",
      "batch : 575\n",
      "batch : 576\n",
      "batch : 577\n",
      "batch : 578\n",
      "batch : 579\n",
      "batch : 580\n",
      "batch : 581\n",
      "batch : 582\n",
      "batch : 583\n",
      "batch : 584\n",
      "batch : 585\n",
      "batch : 586\n",
      "batch : 587\n",
      "batch : 588\n",
      "batch : 589\n",
      "batch : 590\n",
      "batch : 591\n",
      "batch : 592\n",
      "batch : 593\n",
      "batch : 594\n",
      "batch : 595\n",
      "batch : 596\n",
      "batch : 597\n",
      "batch : 598\n",
      "batch : 599\n",
      "batch : 600\n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "Accuracy on all adversarial examples after batch 600: 98.32%\n",
      "too high accuracy on adversarial samples, retraining atn\n",
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 600/600 [00:20<00:00, 29.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       16.6888     0.6639      10.0493     20.24     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 600/600 [00:20<00:00, 29.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       16.3537     0.6585      9.7686      20.26     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 600/600 [00:20<00:00, 29.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       16.2531     0.6627      9.6265      20.26     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 600/600 [00:20<00:00, 29.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       16.2772     0.6741      9.5357      20.24     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 600/600 [00:19<00:00, 30.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       16.2397     0.6782      9.4572      19.77     \n",
      "938/938 [==============================] - 4s 5ms/step\n",
      "How many adversarial samples: 30000\n",
      "ATN retrained, adversarial examples and train_data_with_adv updated.\n",
      "938/938 [==============================] - 4s 4ms/step\n",
      "Target model accuracy on adversarial samples for epoch 2: 98.32%\n"
     ]
    }
   ],
   "source": [
    "global adversarial_examples\n",
    "\n",
    "#first we do the first training of the atn\n",
    "train_atn()\n",
    "\n",
    "fraction = 0.5\n",
    "num_epochs = 2 #changed from 25 to 2 for experimentation reasons now.\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    #determine the indices for adversarial samples\n",
    "    num_samples = len(mnist_train)\n",
    "    num_adversarial = int(fraction * num_samples)\n",
    "    indices = np.random.choice(num_samples, num_adversarial, replace=False)\n",
    "    #create initial subset of adversarial examples. This is made explictly mutable as it can be changed by cnn_train_step after retraining the ATN\n",
    "    train_data_with_adv, adversarial_examples, adv_true_labels = create_partly_adv_data(atn, train_data, indices)  #create adversarial samples per epoch\n",
    "    #adversarial_examples = np.array(adversarial_examples)  # makes copy, Ensures mutability, adv_true_labels does not have to be mutable, since the ATN doesnt change this.\n",
    "    \n",
    "    train_data_iterator = iter(train_data_with_adv) # Create an iterator from the dataset\n",
    "    for batch_number in range(len(train_data_with_adv)): #loop over the number of batches not the data itself as it may change during the loop\n",
    "        print(f\"batch : {batch_number + 1}\")\n",
    "        try:\n",
    "            # Get the next batch\n",
    "            x, labels = next(train_data_iterator)\n",
    "            cnn_train_step(x, labels, adversarial_examples, adv_true_labels, batch_number) #adversarial_examples and adv true labels is only for checking accuracy. Need to modify train_data_with_adv\n",
    "        \n",
    "        except StopIteration:\n",
    "            break # In case the iterator runs out of data\n",
    "            \n",
    "    #do not loop over something that is changing\n",
    "    #for batch_number, (x, labels) in enumerate(train_data_with_adv):  # Loop over batches, train_data_with_adv is already batched\n",
    "    #    cnn_train_step(x, labels, adversarial_examples, adv_true_labels, batch_number) #adversarial_examples and adv true labels is only for checking accuracy. Need to modify train_data_with_adv\n",
    "    \n",
    "    \n",
    "    \n",
    "    #model.fit(train_data_with_adv, epochs=1)\n",
    "    \n",
    "    #check per epoch how well the atn can fool the model\n",
    "    adv_preds_classes = np.argmax(model.predict(adversarial_examples), axis=1)  # Get predicted classes\n",
    "    adv_true_classes = np.argmax(adv_true_labels, axis=1)  # Get true classes #simply comparing accuracy on how much classes are correct. perhaps using cross entropy loss threshold is better\n",
    "    # Calculate accuracy on adversarial examples\n",
    "    adv_accuracy = np.mean(adv_preds_classes == adv_true_classes) * 100 # [True, False, True, True, True], take the mean of that, x100 for percentage\n",
    "    print(f\"Target model accuracy on adversarial samples for epoch {epoch + 1}: {adv_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 12ms/step - loss: 0.0536 - accuracy: 0.9850\n",
      "Test accuracy: 0.9850000143051147\n",
      "summary: \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              3212288   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,274,634\n",
      "Trainable params: 3,274,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data) #dropout is automatically set to 1.0 when calling model.evaluate\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "print(\"summary: \")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('jurjen_adv_training_3_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save the ATN with the generated name\n",
    "atn.save(\"jurjen_ATN_adv_training_3_beta0.01_epochs5_conv2d_transpose.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "7. CNN-MNIST_tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
