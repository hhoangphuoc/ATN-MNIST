{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCL6UCvWmggf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (default, Nov 22 2023, 10:22:35) \n",
      "[GCC 9.4.0]\n",
      "executable: \n",
      "/usr/bin/python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 23:24:39.348145: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-31 23:24:39.462547: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-31 23:24:40.426599: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-31 23:24:40.426668: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-31 23:24:40.426673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "4.9.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(\"executable: \")\n",
    "print(sys.executable)\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow_datasets as tfds\n",
    "print(tfds.__version__)\n",
    "#print(\"TFDS version:\", tfds.__version__)\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "_dUJNbrZmggi",
    "outputId": "3802d63c-a895-4db8-ab3f-6d73da0341ea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = tfds.load('mnist', split=['train', 'test'], as_supervised=True)\n",
    "def preprocess_image(image, label):\n",
    "    #image = image\n",
    "    image = tf.cast(image, tf.float32) \n",
    "    label = tf.one_hot(label, depth=10)  # One-hot encode the label\n",
    "    return image, label\n",
    "mnist_train = mnist_train.map(preprocess_image) #now train is shared among atn and cnn\n",
    "mnist_test = mnist_test.map(preprocess_image)\n",
    "mnist_train_atn = mnist_train.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "mnist_test_atn = mnist_test.batch(32).prefetch(tf.data.AUTOTUNE) #not used now since test is done in other code still"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "The following cells are regarding the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKt0nwHfmggn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#defining the network\n",
    "input_width = 28\n",
    "input_height = 28\n",
    "input_channels = 1\n",
    "input_pixels = 784\n",
    "\n",
    "n_conv1 = 32\n",
    "n_conv2 = 64\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 1\n",
    "conv1_k = 5\n",
    "conv2_k = 5\n",
    "max_pool1_k = 2\n",
    "max_pool2_k = 2\n",
    "\n",
    "n_hidden = 1024\n",
    "n_out = 10\n",
    "\n",
    "input_size_to_hidden = (input_width//(max_pool1_k*max_pool2_k)) * (input_height//(max_pool1_k*max_pool2_k)) *n_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "MYNlFqwTmggp",
    "outputId": "8cef8e57-c1cc-44d7-f067-d2f48268b393",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initialising the weights with random values\n",
    "# NOT USED IN THIS CODE WITH KERAS IMPLEMENTATION\n",
    "weights = {\n",
    "    \"wc1\" : tf.Variable(tf.random.normal([conv1_k, conv1_k, input_channels, n_conv1])),\n",
    "    \"wc2\" : tf.Variable(tf.random.normal([conv2_k, conv2_k, n_conv1, n_conv2])),\n",
    "    \"wh1\" : tf.Variable(tf.random.normal([input_size_to_hidden, n_hidden])),\n",
    "    \"wo\" : tf.Variable(tf.random.normal([n_hidden, n_out]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"bc1\" : tf.Variable(tf.random.normal([n_conv1])),\n",
    "    \"bc2\" : tf.Variable(tf.random.normal([n_conv2])),\n",
    "    \"bh1\" : tf.Variable(tf.random.normal([n_hidden])),\n",
    "    \"bo\" : tf.Variable(tf.random.normal([n_out])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psiAAeeymggr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions for layers\n",
    "def conv(x, weights, bias, strides = 1):\n",
    "    out = tf.nn.conv2d(x, weights, padding=\"SAME\", strides = [1, strides, strides, 1])\n",
    "    out = tf.nn.bias_add(out, bias)\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "\n",
    "def maxpooling(x, k = 2):\n",
    "    return tf.nn.max_pool(x, padding = \"SAME\", ksize = [1, k, k, 1], strides = [1, k, k, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktMBnG1ymggt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function for forward prop\n",
    "#This function is edited now with keras functionality. weights are now handled internally but can still be accessed with get_weights method\n",
    "def cnn(x):\n",
    "    # Define the layers using Keras API\n",
    "    #x = layers.Reshape((input_height, input_width, input_channels))(x)\n",
    "    \n",
    "    conv1 = layers.Conv2D(n_conv1, kernel_size=(conv1_k, conv1_k), strides=stride_conv1, padding=\"same\", activation=\"relu\")(x)\n",
    "    conv1_pool = layers.MaxPooling2D(pool_size=(max_pool1_k, max_pool1_k))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(n_conv2, kernel_size=(conv2_k, conv2_k), strides=stride_conv2, padding=\"same\", activation=\"relu\")(conv1_pool)\n",
    "    conv2_pool = layers.MaxPooling2D(pool_size=(max_pool2_k, max_pool2_k))(conv2)\n",
    "\n",
    "    # Flatten the output from convolutional layers\n",
    "    flatten = layers.Flatten()(conv2_pool)\n",
    "\n",
    "    # Fully connected layer\n",
    "    hidden = layers.Dense(n_hidden, activation=\"relu\")(flatten)\n",
    "\n",
    "    # Dropout\n",
    "    dropout = layers.Dropout(0.2)(hidden)\n",
    "\n",
    "    # Output layer (logits)\n",
    "    output = layers.Dense(n_out, activation = 'softmax')(dropout)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Nd0sB1XOmggv",
    "outputId": "e2817129-39a4-4317-aaf7-0043d729a2ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x = tf.keras.Input(shape=(input_pixels,))\n",
    "x = tf.keras.Input(shape=(input_height, input_width, input_channels))\n",
    "y = tf.keras.Input(shape=(n_out,))\n",
    "#pred is the model\n",
    "pred = cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKNqv-KZmgg0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.Model(inputs=[x], outputs=pred)\n",
    "optimizer_cnn = tf.keras.optimizers.Adam(learning_rate=0.001) #changed from 0.01 to 0.001\n",
    "model.compile(optimizer=optimizer_cnn, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "train_data = mnist_train #it will be given in batches by the create_partly_adv_data method\n",
    "initial_train_data = mnist_train.batch(32)\n",
    "test_data = mnist_test.batch(32)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following code is regarding the ATN and training the ATN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 23:25:09.583863: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 150.06MiB (rounded to 157351936)requested by op StatelessRandomUniformV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-01-31 23:25:09.583910: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2025-01-31 23:25:09.583931: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 41, Chunks in use: 41. 10.2KiB allocated for chunks. 10.2KiB in use in bin. 1.3KiB client-requested in use in bin.\n",
      "2025-01-31 23:25:09.583945: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 512B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.583959: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2025-01-31 23:25:09.583972: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 4, Chunks in use: 3. 11.8KiB allocated for chunks. 8.8KiB in use in bin. 8.5KiB client-requested in use in bin.\n",
      "2025-01-31 23:25:09.583986: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 2, Chunks in use: 2. 10.0KiB allocated for chunks. 10.0KiB in use in bin. 8.0KiB client-requested in use in bin.\n",
      "2025-01-31 23:25:09.583998: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584009: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584023: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 3, Chunks in use: 2. 112.0KiB allocated for chunks. 80.0KiB in use in bin. 80.0KiB client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584036: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 2, Chunks in use: 0. 188.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584050: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 2, Chunks in use: 2. 400.0KiB allocated for chunks. 400.0KiB in use in bin. 400.0KiB client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584063: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 2, Chunks in use: 1. 568.0KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584075: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 576.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584086: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584096: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584107: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584121: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 3, Chunks in use: 2. 35.91MiB allocated for chunks. 24.50MiB in use in bin. 24.50MiB client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584133: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 0. 51.01MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584144: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584155: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584172: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584182: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-31 23:25:09.584198: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 150.06MiB was 128.00MiB, Chunk State: \n",
      "2025-01-31 23:25:09.584207: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 93061120\n",
      "2025-01-31 23:25:09.584222: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000000 of size 1280 next 1\n",
      "2025-01-31 23:25:09.584232: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000500 of size 256 next 7\n",
      "2025-01-31 23:25:09.584240: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000600 of size 256 next 3\n",
      "2025-01-31 23:25:09.584248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000700 of size 256 next 4\n",
      "2025-01-31 23:25:09.584256: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000800 of size 256 next 5\n",
      "2025-01-31 23:25:09.584264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000900 of size 256 next 6\n",
      "2025-01-31 23:25:09.584272: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000a00 of size 256 next 27\n",
      "2025-01-31 23:25:09.584280: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000b00 of size 256 next 8\n",
      "2025-01-31 23:25:09.584288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000c00 of size 256 next 9\n",
      "2025-01-31 23:25:09.584296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000d00 of size 256 next 10\n",
      "2025-01-31 23:25:09.584304: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000e00 of size 256 next 11\n",
      "2025-01-31 23:25:09.584312: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e000f00 of size 256 next 12\n",
      "2025-01-31 23:25:09.584320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e001000 of size 256 next 13\n",
      "2025-01-31 23:25:09.584328: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e001100 of size 256 next 14\n",
      "2025-01-31 23:25:09.584336: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e001200 of size 256 next 15\n",
      "2025-01-31 23:25:09.584344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e001300 of size 256 next 24\n",
      "2025-01-31 23:25:09.584352: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e001400 of size 256 next 25\n",
      "2025-01-31 23:25:09.584361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e001500 of size 6144 next 16\n",
      "2025-01-31 23:25:09.584371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e002d00 of size 3328 next 17\n",
      "2025-01-31 23:25:09.584380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e003a00 of size 256 next 28\n",
      "2025-01-31 23:25:09.584388: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e003b00 of size 256 next 30\n",
      "2025-01-31 23:25:09.584396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e003c00 of size 256 next 29\n",
      "2025-01-31 23:25:09.584404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e003d00 of size 256 next 31\n",
      "2025-01-31 23:25:09.584412: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e003e00 of size 256 next 33\n",
      "2025-01-31 23:25:09.584420: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e003f00 of size 256 next 34\n",
      "2025-01-31 23:25:09.584428: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e004000 of size 256 next 35\n",
      "2025-01-31 23:25:09.584436: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e004100 of size 256 next 38\n",
      "2025-01-31 23:25:09.584444: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e004200 of size 256 next 39\n",
      "2025-01-31 23:25:09.584453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e004300 of size 256 next 40\n",
      "2025-01-31 23:25:09.584461: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e004400 of size 256 next 43\n",
      "2025-01-31 23:25:09.584470: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e004500 of size 256 next 44\n",
      "2025-01-31 23:25:09.584477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e004600 of size 256 next 47\n",
      "2025-01-31 23:25:09.584485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e004700 of size 256 next 48\n",
      "2025-01-31 23:25:09.584493: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e004800 of size 256 next 49\n",
      "2025-01-31 23:25:09.584501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e004900 of size 256 next 2\n",
      "2025-01-31 23:25:09.584510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e004a00 of size 4096 next 26\n",
      "2025-01-31 23:25:09.584518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e005a00 of size 3328 next 32\n",
      "2025-01-31 23:25:09.584526: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd59e006700 of size 70400 next 22\n",
      "2025-01-31 23:25:09.584535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e017a00 of size 40960 next 23\n",
      "2025-01-31 23:25:09.584544: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd59e021a00 of size 286720 next 18\n",
      "2025-01-31 23:25:09.584553: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e067a00 of size 204800 next 19\n",
      "2025-01-31 23:25:09.584561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e099a00 of size 256 next 50\n",
      "2025-01-31 23:25:09.584569: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e099b00 of size 256 next 51\n",
      "2025-01-31 23:25:09.584577: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e099c00 of size 256 next 53\n",
      "2025-01-31 23:25:09.584585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e099d00 of size 256 next 54\n",
      "2025-01-31 23:25:09.584593: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e099e00 of size 256 next 52\n",
      "2025-01-31 23:25:09.584601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e099f00 of size 512 next 59\n",
      "2025-01-31 23:25:09.584609: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e09a100 of size 256 next 55\n",
      "2025-01-31 23:25:09.584617: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e09a200 of size 256 next 58\n",
      "2025-01-31 23:25:09.584625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e09a300 of size 256 next 62\n",
      "2025-01-31 23:25:09.584633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e09a400 of size 256 next 63\n",
      "2025-01-31 23:25:09.584642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd59e09a500 of size 3072 next 56\n",
      "2025-01-31 23:25:09.584650: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e09b100 of size 2304 next 57\n",
      "2025-01-31 23:25:09.584659: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd59e09ba00 of size 32768 next 46\n",
      "2025-01-31 23:25:09.584667: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e0a3a00 of size 40960 next 45\n",
      "2025-01-31 23:25:09.584675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd59e0ada00 of size 122880 next 37\n",
      "2025-01-31 23:25:09.584683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59e0cba00 of size 204800 next 36\n",
      "2025-01-31 23:25:09.584692: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd59e0fda00 of size 25280512 next 20\n",
      "2025-01-31 23:25:09.584701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd59f919a00 of size 12845056 next 21\n",
      "2025-01-31 23:25:09.584709: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd5a0559a00 of size 589824 next 61\n",
      "2025-01-31 23:25:09.584719: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd5a05e9a00 of size 294912 next 60\n",
      "2025-01-31 23:25:09.584729: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd5a0631a00 of size 11960320 next 42\n",
      "2025-01-31 23:25:09.584737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd5a1199a00 of size 12845056 next 41\n",
      "2025-01-31 23:25:09.584746: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd5a1dd9a00 of size 28206592 next 18446744073709551615\n",
      "2025-01-31 23:25:09.584755: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2025-01-31 23:25:09.584767: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 41 Chunks of size 256 totalling 10.2KiB\n",
      "2025-01-31 23:25:09.584779: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 512 totalling 512B\n",
      "2025-01-31 23:25:09.584788: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2025-01-31 23:25:09.584798: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2304 totalling 2.2KiB\n",
      "2025-01-31 23:25:09.584807: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 3328 totalling 6.5KiB\n",
      "2025-01-31 23:25:09.584817: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 4096 totalling 4.0KiB\n",
      "2025-01-31 23:25:09.584826: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 6144 totalling 6.0KiB\n",
      "2025-01-31 23:25:09.584836: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 40960 totalling 80.0KiB\n",
      "2025-01-31 23:25:09.584846: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 204800 totalling 400.0KiB\n",
      "2025-01-31 23:25:09.584856: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 294912 totalling 288.0KiB\n",
      "2025-01-31 23:25:09.584866: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 12845056 totalling 24.50MiB\n",
      "2025-01-31 23:25:09.584877: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 25.28MiB\n",
      "2025-01-31 23:25:09.584886: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 93061120 memory_limit_: 93061120 available bytes: 0 curr_region_allocation_bytes_: 186122240\n",
      "2025-01-31 23:25:09.584904: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                        93061120\n",
      "InUse:                        26508032\n",
      "MaxInUse:                     64284928\n",
      "NumAllocs:                         105\n",
      "MaxAllocSize:                 25280512\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-01-31 23:25:09.584923: W tensorflow/tsl/framework/bfc_allocator.cc:492] **__________________________****************___________***************______________________________\n",
      "2025-01-31 23:25:09.584964: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at stateless_random_ops_v2.cc:67 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[6272,6272] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL _NotOkStatusException REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/core.py(36): __init__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_stateless_random_ops_v2.py(475): stateless_random_uniform_v2\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/stateless_random_ops.py(501): stateless_random_uniform\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py(1176): op_dispatch_handler\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.8/dist-packages/keras/backend.py(2100): random_uniform\n  /usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py(662): _generate_init_val\n  /usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py(637): __call__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/resource_variable_ops.py(1905): _init_from_args\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/resource_variable_ops.py(1721): __init__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py(273): __call__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variable_scope.py(2706): default_variable_creator\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py(203): <lambda>\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py(210): _variable_v1_call\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py(269): __call__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer_utils.py(134): make_variable\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/trackable/base.py(489): _add_variable_with_custom_getter\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(711): add_weight\n  /usr/local/lib/python3.8/dist-packages/keras/layers/core/dense.py(154): build\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(2986): _maybe_build\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(2439): _infer_output_signature\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(2382): _keras_tensor_symbolic_call\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(2535): _functional_construction_call\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(1045): __call__\n  /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py(65): error_handler\n  /usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py(237): add\n  /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py(65): error_handler\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/trackable/base.py(205): _method_wrapper\n  /usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py(143): __init__\n  /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py(65): error_handler\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/trackable/base.py(205): _method_wrapper\n  /tmp/ipykernel_150/1617499980.py(3): build_atn\n  /tmp/ipykernel_150/1617499980.py(27): <module>\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3508): run_code\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3448): run_ast_nodes\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3269): run_cell_async\n  /usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3064): _run_cell\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3009): run_cell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py(549): run_cell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(449): do_execute\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(778): execute_request\n  /usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(362): execute_request\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(437): dispatch_shell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(534): process_one\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(545): dispatch_queue\n  /usr/lib/python3.8/asyncio/events.py(81): _run\n  /usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py(205): start\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py(739): start\n  /usr/local/lib/python3.8/dist-packages/traitlets/config/application.py(1075): launch_instance\n  /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py(18): <module>\n  /usr/lib/python3.8/runpy.py(87): _run_code\n  /usr/lib/python3.8/runpy.py(194): _run_module_as_main\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Build the ATN\u001b[39;00m\n\u001b[1;32m     26\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# MNIST dataset shape\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m atn \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_atn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m, in \u001b[0;36mbuild_atn\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_atn\u001b[39m(input_shape):\n\u001b[0;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# First convolutional layers to capture features\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMaxPooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Downsample (14, 14, 64)\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMaxPooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Downsample (7, 7, 128)\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Fully connected layer to integrate features\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFlatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Flatten to shape (7 * 7 * 128 = 6272)\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6272\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Match the reshape target\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Deconvolution layers to reconstruct adversarial examples\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reshape for deconvolution\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2DTranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (14, 14, 128)\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2DTranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (28, 28, 64)\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2DTranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msigmoid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Output layer (28, 28, 1)\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Scale to [0, 255]\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[1;32m   2099\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m   2108\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   2109\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2113\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL _NotOkStatusException REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/core.py(36): __init__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_stateless_random_ops_v2.py(475): stateless_random_uniform_v2\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/stateless_random_ops.py(501): stateless_random_uniform\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py(1176): op_dispatch_handler\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.8/dist-packages/keras/backend.py(2100): random_uniform\n  /usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py(662): _generate_init_val\n  /usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py(637): __call__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/resource_variable_ops.py(1905): _init_from_args\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/resource_variable_ops.py(1721): __init__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py(273): __call__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variable_scope.py(2706): default_variable_creator\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py(203): <lambda>\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py(210): _variable_v1_call\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py(269): __call__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer_utils.py(134): make_variable\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/trackable/base.py(489): _add_variable_with_custom_getter\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(711): add_weight\n  /usr/local/lib/python3.8/dist-packages/keras/layers/core/dense.py(154): build\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(2986): _maybe_build\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(2439): _infer_output_signature\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(2382): _keras_tensor_symbolic_call\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(2535): _functional_construction_call\n  /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py(1045): __call__\n  /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py(65): error_handler\n  /usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py(237): add\n  /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py(65): error_handler\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/trackable/base.py(205): _method_wrapper\n  /usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py(143): __init__\n  /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py(65): error_handler\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/trackable/base.py(205): _method_wrapper\n  /tmp/ipykernel_150/1617499980.py(3): build_atn\n  /tmp/ipykernel_150/1617499980.py(27): <module>\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3508): run_code\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3448): run_ast_nodes\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3269): run_cell_async\n  /usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3064): _run_cell\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3009): run_cell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py(549): run_cell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(449): do_execute\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(778): execute_request\n  /usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(362): execute_request\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(437): dispatch_shell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(534): process_one\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(545): dispatch_queue\n  /usr/lib/python3.8/asyncio/events.py(81): _run\n  /usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py(205): start\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py(739): start\n  /usr/local/lib/python3.8/dist-packages/traitlets/config/application.py(1075): launch_instance\n  /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py(18): <module>\n  /usr/lib/python3.8/runpy.py(87): _run_code\n  /usr/lib/python3.8/runpy.py(194): _run_module_as_main\n"
     ]
    }
   ],
   "source": [
    "# @ layers with 2 deconvolution layers\n",
    "def build_atn(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        # First convolutional layers to capture features\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),  # Downsample (14, 14, 64)\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),  # Downsample (7, 7, 128)\n",
    "\n",
    "        # Fully connected layer to integrate features\n",
    "        layers.Flatten(),  # Flatten to shape (7 * 7 * 128 = 6272)\n",
    "        layers.Dense(6272, activation='relu'),  # Match the reshape target\n",
    "\n",
    "        # Deconvolution layers to reconstruct adversarial examples\n",
    "        layers.Reshape((7, 7, 128)),  # Reshape for deconvolution\n",
    "        layers.Conv2DTranspose(128, (3, 3), activation='relu', strides=2, padding='same'),  # (14, 14, 128)\n",
    "        layers.Conv2DTranspose(64, (3, 3), activation='relu', strides=2, padding='same'),  # (28, 28, 64)\n",
    "        \n",
    "        layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same'),  # Output layer (28, 28, 1)\n",
    "        layers.Lambda(lambda x: x * 255)  # Scale to [0, 255]\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Build the ATN\n",
    "input_shape = (28, 28, 1)  # MNIST dataset shape\n",
    "atn = build_atn(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define input loss and output loss function\n",
    "def input_loss(x, x_prime):\n",
    "    return tf.reduce_mean(tf.square(tf.cast(x, tf.float32) - x_prime))  # Cast x to float32  # L2 loss\n",
    "\n",
    "def output_loss(y_pred, y_target):\n",
    "    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_target, y_pred)) # crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the models\n",
    "input_img = tf.keras.Input(shape=input_shape)\n",
    "x_prime = atn(input_img)\n",
    "y_pred = model(x_prime)\n",
    "\n",
    "combined_model = tf.keras.Model(inputs=input_img, outputs=[x_prime, y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_second_highest_target(y_pred_original, target_class=None):\n",
    "    top_2_indices = tf.argsort(y_pred_original, direction='DESCENDING', axis=1)[:, :2]\n",
    "    second_highest_indices = top_2_indices[:, 1]\n",
    "    # Create one-hot encoding for the second-highest class\n",
    "    y_target = tf.one_hot(second_highest_indices, depth=y_pred_original.shape[1])\n",
    "    return y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training procedure\n",
    "optimizer_atn = tf.keras.optimizers.Adam(learning_rate=0.0001) #hier is ook niet de loss function geinitialiseerd. learning rate verandert naar 0.0001 ipv dynamisch,0.0001 is uit paper\n",
    "beta = 0.001  # Weight for input-space loss #changed from  #changed from 0.001 to 0.01\n",
    "\n",
    "@tf.function\n",
    "def atn_train_step(x, y_original):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Generate adversarial examples\n",
    "        x_prime = atn(x)\n",
    "        l_x = input_loss(x, x_prime)\n",
    "        # Get predictions for original and adversarial inputs\n",
    "        y_pred_original = model(x, training=False)\n",
    "        y_pred = model(x_prime, training=False)\n",
    "\n",
    "        # Compute the second-highest target dynamically\n",
    "        y_target = get_second_highest_target(y_pred_original)\n",
    "\n",
    "        # Compute input loss and output loss separately\n",
    "        \n",
    "        l_y = output_loss(y_pred, y_target)\n",
    "\n",
    "        # Compute the combined loss\n",
    "        loss = beta * l_x + l_y\n",
    "\n",
    "    # Compute and apply gradients\n",
    "    gradients = tape.gradient(loss, atn.trainable_variables)\n",
    "    optimizer_atn.apply_gradients(zip(gradients, atn.trainable_variables))\n",
    "\n",
    "    # Return total loss, input loss, and output loss\n",
    "    return loss, l_x, l_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "def train_atn():\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 20 #for experiment reasons, changed from 100 to 3 now\n",
    "    batch_size = 32\n",
    "    #beta = 0.1 #this beta is purely for scaling purposes of the output. change beta at atn_train-step\n",
    "    #optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    print(f\"{'Epoch':<8}{'Total Loss':<12}{'Scaled Input Loss':<12}{'Output Loss':<12}{'Time (s)':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        atn_start_time = time()\n",
    "        epoch_loss = 0\n",
    "        epoch_input_loss = 0\n",
    "        epoch_output_loss = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        # Add progress bar for batches\n",
    "        for x_batch, y_original_batch in tqdm(mnist_train_atn, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "            loss, l_x, l_y = atn_train_step(x_batch, y_original_batch)  # Get all losses\n",
    "            epoch_loss += loss.numpy()\n",
    "            epoch_input_loss += l_x.numpy()*0.01 #beta is already applied at atn_train_step\n",
    "            epoch_output_loss += l_y.numpy()\n",
    "            batch_count += 1\n",
    "\n",
    "        # Compute average losses for the epoch\n",
    "        avg_loss = epoch_loss / batch_count\n",
    "        avg_input_loss = epoch_input_loss / batch_count\n",
    "        avg_output_loss = epoch_output_loss / batch_count\n",
    "        elapsed_time = time() - atn_start_time\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"{epoch + 1:<8}{avg_loss:<12.4f}{avg_input_loss:<12.4f}{avg_output_loss:<12.4f}{elapsed_time:<10.2f}\")\n",
    "        # Manually apply the ReduceLROnPlateau scheduler\n",
    "        #if lr_scheduler is not None:\n",
    "        #    lr_scheduler.on_epoch_end(epoch, logs={'loss': avg_loss})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following code is regarding training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_samples(original, adversarial, index=None):\n",
    "    \"\"\"\n",
    "    Visualize original and adversarial samples side-by-side.\n",
    "    \n",
    "    Args:\n",
    "        original (np.array): The original sample (e.g., shape (28, 28, 1)).\n",
    "        adversarial (np.array): The adversarial sample (same shape as original).\n",
    "        index (int, optional): The index of the sample (useful for debugging).\n",
    "    \"\"\"\n",
    "    original = np.squeeze(original)  # Remove extra dimensions if present\n",
    "    adversarial = np.squeeze(adversarial)  # Remove extra dimensions if present\n",
    "    \n",
    "    # Set up the plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    fig.suptitle(f\"Original vs. Adversarial (Index: {index})\", fontsize=16)\n",
    "    \n",
    "    # Plot original\n",
    "    axs[0].imshow(original, cmap='gray')\n",
    "    axs[0].set_title(\"Original\")\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Plot adversarial\n",
    "    axs[1].imshow(adversarial, cmap='gray')\n",
    "    axs[1].set_title(\"Adversarial\")\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Added this cell for adversarial training\n",
    "#keras.config.enable_unsafe_deserialization()\n",
    "#atn = tf.keras.models.load_model('jurjen_adversarial_transformation_network_beta-0.01_epochs-50_conv2d_transpose.keras')\n",
    "#prev method see experiment 6\n",
    "def create_partly_adv_data(atn, dataset, indices):\n",
    "    mnist_train_images = np.array([x.numpy() for x, y in dataset]) #as i make a copy, this is safe\n",
    "    mnist_train_labels = np.array([y.numpy() for x, y in dataset])\n",
    "    #random should ensure every epoch new images are used to generate adversarial samples\n",
    "    adversarial_samples = atn.predict(mnist_train_images[indices]) #get list of x prime's\n",
    "    print(f\"How many adversarial samples: {len(adversarial_samples)}\")\n",
    "    mnist_train_images[indices] = adversarial_samples #no condition checking here, its easier (biggest difference with experiment 6\n",
    "    #recreate the tf.data.Dataset with the modified data\n",
    "    updated_mnist_train = tf.data.Dataset.from_tensor_slices((mnist_train_images, mnist_train_labels)).batch(32) #return it in batches of 100\n",
    "    return updated_mnist_train, adversarial_samples, mnist_train_labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cnn_train_step(batch_data, batch_labels, adversarial_samples, adversarial_labels, batchnumber):\n",
    "    \n",
    "    # Train the model on the current batch\n",
    "    model.train_on_batch(batch_data, batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#first train cnn model briefly so ATN can start training on that checkpoint\n",
    "model.fit(initial_train_data, epochs=10) #20 naar 5\n",
    "\n",
    "#train the atn on the checkpoint\n",
    "model.trainable = False\n",
    "train_atn()\n",
    "model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'atn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#from time import time\u001b[39;00m\n\u001b[1;32m      5\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43matn\u001b[49m\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m#dit moet je veranderen als hij straks hertraind moet \u001b[39;00m\n\u001b[1;32m      7\u001b[0m fraction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m      8\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m70\u001b[39m \u001b[38;5;66;03m#changed from 25 to 3 for experimentation reasons now. #perhaps do multiple epochs if retrain ATN after 2 epochs\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'atn' is not defined"
     ]
    }
   ],
   "source": [
    "#global adversarial_examples\n",
    "import sys\n",
    "#from time import time\n",
    "\n",
    "count = 0\n",
    "atn.trainable = False #dit moet je veranderen als hij straks hertraind moet \n",
    "fraction = 0.5\n",
    "num_epochs = 70 #changed from 25 to 3 for experimentation reasons now. #perhaps do multiple epochs if retrain ATN after 2 epochs\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_start_time = time()\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    #determine indices of adv examples\n",
    "    num_samples = len(mnist_train)\n",
    "    num_adversarial = int(fraction * num_samples)\n",
    "    indices = np.random.choice(num_samples, num_adversarial, replace=False)\n",
    "    train_data_with_adv, adversarial_examples, adv_true_labels = create_partly_adv_data(atn, train_data, indices) \n",
    "    train_data_iterator = iter(train_data_with_adv) # Create an iterator from the dataset\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    \n",
    "    for batch_number in range(len(train_data_with_adv)): #loop over the number of batches not the data itself as it may change during the loop\n",
    "        #print(f\"batch : {batch_number + 1}\")\n",
    "        try:\n",
    "            # Get the next batch\n",
    "            x, labels = next(train_data_iterator)\n",
    "            loss, accuracy = model.train_on_batch(x, labels)\n",
    "            \n",
    "            total_loss += loss\n",
    "            total_accuracy += accuracy\n",
    "            # Progress bar display\n",
    "            progress = int((batch_number + 1) / len(train_data_with_adv) * 30)  # Progress bar length (30 characters)\n",
    "            sys.stdout.write(\n",
    "                f\"\\r[{'=' * progress}{'.' * (30 - progress)}] \"\n",
    "                f\"{batch_number + 1}/{len(train_data_with_adv)} - loss: {loss:.4f} - accuracy: {accuracy:.4f}\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        except StopIteration:\n",
    "            break # In case the iterator runs out of data\n",
    "            \n",
    "    # End of epoch metrics CNN\n",
    "    avg_loss = total_loss / len(train_data_with_adv)\n",
    "    avg_accuracy = total_accuracy / len(train_data_with_adv)\n",
    "    elapsed_time = time() - cnn_start_time\n",
    "    print(f\"\\nEpoch {epoch + 1} completed in {elapsed_time:.2f}s - loss: {avg_loss:.4f} - accuracy: {avg_accuracy:.4f}\")\n",
    "    \n",
    "    #check per epoch how well the atn can fool the model\n",
    "    adv_preds_classes = np.argmax(model.predict(adversarial_examples), axis=1)  # Get predicted classes\n",
    "    adv_true_classes = np.argmax(adv_true_labels, axis=1)  # Get true classes #simply comparing accuracy on how much classes are correct. perhaps using cross entropy loss threshold is better\n",
    "    # Calculate accuracy on adversarial examples\n",
    "    adv_accuracy = np.mean(adv_preds_classes == adv_true_classes) * 100 # [True, False, True, True, True], take the mean of that, x100 for percentage\n",
    "    print(f\"Target model accuracy on adversarial samples for epoch {epoch + 1}: {adv_accuracy:.2f}%\")\n",
    "    if adv_accuracy > 95 and count < 20:\n",
    "        print(\"Too high accuracy, retrain ATN\")\n",
    "        #atn = build_atn((28, 28, 1)) #reset the atn\n",
    "        #optimizer_atn = tf.keras.optimizers.Adam(learning_rate=0.0001) #reset optimizer_atn\n",
    "        atn.trainable = True\n",
    "        model.trainable = False\n",
    "        train_atn() #instead of train from scratch, retrain\n",
    "        atn.trainable = False\n",
    "        model.trainable = True\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 23:25:23.757015: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2025-01-31 23:25:23.757086: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Possibly insufficient driver version: 555.42.6\n",
      "2025-01-31 23:25:23.757120: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops_fused_impl.h:621 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL UnimplementedError REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/errors_impl.py(445): __init__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py(52): quick_execute\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py(378): call\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py(1745): _call_flat\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py(134): __call__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(945): _call\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(880): __call__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.8/dist-packages/keras/engine/training.py(2040): evaluate\n  /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py(65): error_handler\n  /tmp/ipykernel_150/1942542942.py(1): <module>\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3508): run_code\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3448): run_ast_nodes\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3269): run_cell_async\n  /usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3064): _run_cell\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3009): run_cell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py(549): run_cell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(449): do_execute\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(778): execute_request\n  /usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(362): execute_request\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(437): dispatch_shell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(534): process_one\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(545): dispatch_queue\n  /usr/lib/python3.8/asyncio/events.py(81): _run\n  /usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py(205): start\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py(739): start\n  /usr/local/lib/python3.8/dist-packages/traitlets/config/application.py(1075): launch_instance\n  /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py(18): <module>\n  /usr/lib/python3.8/runpy.py(87): _run_code\n  /usr/lib/python3.8/runpy.py(194): _run_module_as_main\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#dropout is automatically set to 1.0 when calling model.evaluate\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL UnimplementedError REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/errors_impl.py(445): __init__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py(52): quick_execute\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py(378): call\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py(1745): _call_flat\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py(134): __call__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(945): _call\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(880): __call__\n  /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.8/dist-packages/keras/engine/training.py(2040): evaluate\n  /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py(65): error_handler\n  /tmp/ipykernel_150/1942542942.py(1): <module>\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3508): run_code\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3448): run_ast_nodes\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3269): run_cell_async\n  /usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3064): _run_cell\n  /usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3009): run_cell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py(549): run_cell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(449): do_execute\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(778): execute_request\n  /usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(362): execute_request\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(437): dispatch_shell\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(534): process_one\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(545): dispatch_queue\n  /usr/lib/python3.8/asyncio/events.py(81): _run\n  /usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py(205): start\n  /usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py(739): start\n  /usr/local/lib/python3.8/dist-packages/traitlets/config/application.py(1075): launch_instance\n  /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py(18): <module>\n  /usr/lib/python3.8/runpy.py(87): _run_code\n  /usr/lib/python3.8/runpy.py(194): _run_module_as_main\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data) #dropout is automatically set to 1.0 when calling model.evaluate\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "print(\"summary: \")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('Joint_Training_AT.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save the ATN with the generated name\n",
    "atn.save(\"Joint_Training_ATN.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "7. CNN-MNIST_tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
