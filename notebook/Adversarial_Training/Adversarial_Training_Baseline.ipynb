{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCL6UCvWmggf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (default, Nov 22 2023, 10:22:35) \n",
      "[GCC 9.4.0]\n",
      "executable: \n",
      "/usr/bin/python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 23:10:22.929466: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-31 23:10:23.044242: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-31 23:10:24.246452: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-31 23:10:24.246509: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-31 23:10:24.246513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "4.9.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(\"executable: \")\n",
    "print(sys.executable)\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow_datasets as tfds\n",
    "print(tfds.__version__)\n",
    "#print(\"TFDS version:\", tfds.__version__)\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "_dUJNbrZmggi",
    "outputId": "3802d63c-a895-4db8-ab3f-6d73da0341ea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = tfds.load('mnist', split=['train', 'test'], as_supervised=True)\n",
    "def preprocess_image(image, label):\n",
    "    image = image\n",
    "    #image = tf.cast(image, tf.float32) / 255.0  \n",
    "    label = tf.one_hot(label, depth=10)  # One-hot encode the label\n",
    "    return image, label\n",
    "mnist_train = mnist_train.map(preprocess_image)\n",
    "mnist_test = mnist_test.map(preprocess_image)\n",
    "num_train_samples = len(list(mnist_train))\n",
    "mnist_train = mnist_train.take(num_train_samples // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKt0nwHfmggn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#defining the network\n",
    "input_width = 28\n",
    "input_height = 28\n",
    "input_channels = 1\n",
    "input_pixels = 784\n",
    "\n",
    "n_conv1 = 32\n",
    "n_conv2 = 64\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 1\n",
    "conv1_k = 5\n",
    "conv2_k = 5\n",
    "max_pool1_k = 2\n",
    "max_pool2_k = 2\n",
    "\n",
    "n_hidden = 1024\n",
    "n_out = 10\n",
    "\n",
    "input_size_to_hidden = (input_width//(max_pool1_k*max_pool2_k)) * (input_height//(max_pool1_k*max_pool2_k)) *n_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "MYNlFqwTmggp",
    "outputId": "8cef8e57-c1cc-44d7-f067-d2f48268b393",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initialising the weights with random values\n",
    "# NOT USED IN THIS CODE WITH KERAS IMPLEMENTATION\n",
    "weights = {\n",
    "    \"wc1\" : tf.Variable(tf.random.normal([conv1_k, conv1_k, input_channels, n_conv1])),\n",
    "    \"wc2\" : tf.Variable(tf.random.normal([conv2_k, conv2_k, n_conv1, n_conv2])),\n",
    "    \"wh1\" : tf.Variable(tf.random.normal([input_size_to_hidden, n_hidden])),\n",
    "    \"wo\" : tf.Variable(tf.random.normal([n_hidden, n_out]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"bc1\" : tf.Variable(tf.random.normal([n_conv1])),\n",
    "    \"bc2\" : tf.Variable(tf.random.normal([n_conv2])),\n",
    "    \"bh1\" : tf.Variable(tf.random.normal([n_hidden])),\n",
    "    \"bo\" : tf.Variable(tf.random.normal([n_out])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psiAAeeymggr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions for layers\n",
    "def conv(x, weights, bias, strides = 1):\n",
    "    out = tf.nn.conv2d(x, weights, padding=\"SAME\", strides = [1, strides, strides, 1])\n",
    "    out = tf.nn.bias_add(out, bias)\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "\n",
    "def maxpooling(x, k = 2):\n",
    "    return tf.nn.max_pool(x, padding = \"SAME\", ksize = [1, k, k, 1], strides = [1, k, k, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktMBnG1ymggt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function for forward prop\n",
    "#This function is edited now with keras functionality. weights are now handled internally but can still be accessed with get_weights method\n",
    "def cnn(x):\n",
    "    # Define the layers using Keras API\n",
    "    #x = layers.Reshape((input_height, input_width, input_channels))(x)\n",
    "    \n",
    "    conv1 = layers.Conv2D(n_conv1, kernel_size=(conv1_k, conv1_k), strides=stride_conv1, padding=\"same\", activation=\"relu\")(x)\n",
    "    conv1_pool = layers.MaxPooling2D(pool_size=(max_pool1_k, max_pool1_k))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(n_conv2, kernel_size=(conv2_k, conv2_k), strides=stride_conv2, padding=\"same\", activation=\"relu\")(conv1_pool)\n",
    "    conv2_pool = layers.MaxPooling2D(pool_size=(max_pool2_k, max_pool2_k))(conv2)\n",
    "\n",
    "    # Flatten the output from convolutional layers\n",
    "    flatten = layers.Flatten()(conv2_pool)\n",
    "\n",
    "    # Fully connected layer\n",
    "    hidden = layers.Dense(n_hidden, activation=\"relu\")(flatten)\n",
    "\n",
    "    # Dropout\n",
    "    dropout = layers.Dropout(0.2)(hidden)\n",
    "\n",
    "    # Output layer (logits)\n",
    "    output = layers.Dense(n_out, activation = 'softmax')(dropout)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Nd0sB1XOmggv",
    "outputId": "e2817129-39a4-4317-aaf7-0043d729a2ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x = tf.keras.Input(shape=(input_pixels,))\n",
    "x = tf.keras.Input(shape=(input_height, input_width, input_channels))\n",
    "y = tf.keras.Input(shape=(n_out,))\n",
    "#pred is the model\n",
    "pred = cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKNqv-KZmgg0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.Model(inputs=[x], outputs=pred)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) #changed from 0.01 to 0.001\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "train_data = mnist_train #it will be given in batches by the create_partly_adv_data method\n",
    "test_data = mnist_test.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Added this cell for adversarial training\n",
    "\n",
    "atn = tf.keras.models.load_model('ATN_base_model_2NDHALF.keras')\n",
    "\n",
    "def create_partly_adv_data(atn, dataset, fraction=0.5):\n",
    "    mnist_train_images = np.array([x.numpy() for x, y in dataset])\n",
    "    mnist_train_labels = np.array([y.numpy() for x, y in dataset])\n",
    "    num_samples = len(mnist_train_images)\n",
    "    num_adversarial = int(fraction * num_samples)\n",
    "    indices = np.random.choice(num_samples, num_adversarial, replace=False) #random should ensure every epoch new images are used to generate adversarial samples\n",
    "    print(len(indices))\n",
    "    adversarial_examples = atn.predict(mnist_train_images[indices])\n",
    "    mnist_train_images[indices] = adversarial_examples\n",
    "    # Optionally, recreate the tf.data.Dataset with the modified data\n",
    "    updated_mnist_train = tf.data.Dataset.from_tensor_slices((mnist_train_images, mnist_train_labels)).batch(32) #return it in batches of 100\n",
    "    return updated_mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py:777\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    776\u001b[0m   \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m--> 777\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_element_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_compatible_tensor_list\u001b[49m(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute '_from_compatible_tensor_list'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     train_data_with_adv \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_partly_adv_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43matn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(train_data_with_adv, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m, in \u001b[0;36mcreate_partly_adv_data\u001b[0;34m(atn, dataset, fraction)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_partly_adv_data\u001b[39m(atn, dataset, fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     mnist_train_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([x\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[1;32m      7\u001b[0m     mnist_train_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([y\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[1;32m      8\u001b[0m     num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(mnist_train_images)\n",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_partly_adv_data\u001b[39m(atn, dataset, fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     mnist_train_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([x\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[1;32m      7\u001b[0m     mnist_train_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([y\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[1;32m      8\u001b[0m     num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(mnist_train_images)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py:787\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    786\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py:779\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 779\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_compatible_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_element_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/util/structure.py:246\u001b[0m, in \u001b[0;36mfrom_compatible_tensor_list\u001b[0;34m(element_spec, tensor_list)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns an element constructed from the given spec and tensor list.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m    the given spec does not match the given number of tensors.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_tensor_list_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_compatible_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43melement_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/util/structure.py:223\u001b[0m, in \u001b[0;36m_from_tensor_list_helper\u001b[0;34m(decode_fn, element_spec, tensor_list)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (component_spec, num_flat_values) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_specs, flat_spec_lengths):\n\u001b[1;32m    222\u001b[0m   value \u001b[38;5;241m=\u001b[39m tensor_list[i:i \u001b[38;5;241m+\u001b[39m num_flat_values]\n\u001b[0;32m--> 223\u001b[0m   flat_ret\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdecode_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    224\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_flat_values\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(element_spec, flat_ret)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/util/structure.py:247\u001b[0m, in \u001b[0;36mfrom_compatible_tensor_list.<locals>.<lambda>\u001b[0;34m(spec, value)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns an element constructed from the given spec and tensor list.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m    the given spec does not match the given number of tensors.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _from_tensor_list_helper(\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m spec, value: \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_compatible_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    248\u001b[0m     element_spec, tensor_list)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/tensor_spec.py:241\u001b[0m, in \u001b[0;36mTensorSpec._from_compatible_tensor_list\u001b[0;34m(self, tensor_list)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_compatible_tensor_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_list):\n\u001b[1;32m    234\u001b[0m   \u001b[38;5;66;03m# TODO(b/112266545): It would be cleaner to create a new `ensure_shape()`\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   \u001b[38;5;66;03m# op here and return that, instead of mutating the input's shape using\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[38;5;66;03m# the `ensure_shape()` ops and optimize them away using contextual shape\u001b[39;00m\n\u001b[1;32m    239\u001b[0m   \u001b[38;5;66;03m# information.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 241\u001b[0m   \u001b[43mtensor_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tensor_list[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1298\u001b[0m, in \u001b[0;36m_EagerTensorBase.set_shape\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape):\n\u001b[0;32m-> 1298\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241m.\u001b[39mis_compatible_with(shape):\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not compatible \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1300\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith supplied shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1259\u001b[0m, in \u001b[0;36m_EagerTensorBase.shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=access-member-before-definition\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;66;03m# `_tensor_shape` is declared and defined in the definition of\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;66;03m# `EagerTensor`, in C.\u001b[39;00m\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_shape \u001b[38;5;241m=\u001b[39m tensor_shape\u001b[38;5;241m.\u001b[39mTensorShape(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape_tuple\u001b[49m())\n\u001b[1;32m   1260\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for i in range(num_epochs):\n",
    "    print(f\"Epoch {i + 1}/{num_epochs}\")\n",
    "    train_data_with_adv = create_partly_adv_data(atn, train_data, 0.5)\n",
    "    model.fit(train_data_with_adv, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data) #dropout is automatically set to 1.0 when calling model.evaluate\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "print(\"summary: \")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('Baseline_AT.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "7. CNN-MNIST_tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
