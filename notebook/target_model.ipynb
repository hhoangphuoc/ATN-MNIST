{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-datasets in /home/jovyan/.local/lib/python3.8/site-packages (4.9.2)\n",
      "Requirement already satisfied: absl-py in /home/jovyan/.local/lib/python3.8/site-packages (from tensorflow-datasets) (1.4.0)\n",
      "Requirement already satisfied: array-record in /home/jovyan/.local/lib/python3.8/site-packages (from tensorflow-datasets) (0.4.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /home/jovyan/.local/lib/python3.8/site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: etils>=0.9.0 in /home/jovyan/.local/lib/python3.8/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.23.1)\n",
      "Requirement already satisfied: promise in /home/jovyan/.local/lib/python3.8/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/jovyan/.local/lib/python3.8/site-packages (from tensorflow-datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (5.9.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/jovyan/.local/lib/python3.8/site-packages (from tensorflow-datasets) (1.14.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (2.4.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (4.66.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (6.4.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (4.11.0)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (3.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2019.11.28)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from promise->tensorflow-datasets) (1.14.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/jovyan/.local/lib/python3.8/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.66.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCL6UCvWmggf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 20:10:53.867063: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-12 20:10:54.012848: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-12 20:10:54.819050: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-12 20:10:54.819125: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-12 20:10:54.819130: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "# from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "_dUJNbrZmggi",
    "outputId": "3802d63c-a895-4db8-ab3f-6d73da0341ea",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 20:11:02.353646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12688 MB memory:  -> device: 0, name: NVIDIA A16, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2025-01-12 20:11:02.355907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13232 MB memory:  -> device: 1, name: NVIDIA A16, pci bus id: 0000:1c:00.0, compute capability: 8.6\n",
      "2025-01-12 20:11:02.357967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 13232 MB memory:  -> device: 2, name: NVIDIA A16, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2025-01-12 20:11:02.360025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 13232 MB memory:  -> device: 3, name: NVIDIA A16, pci bus id: 0000:1e:00.0, compute capability: 8.6\n",
      "2025-01-12 20:11:02.362134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 13232 MB memory:  -> device: 4, name: NVIDIA A16, pci bus id: 0000:ce:00.0, compute capability: 8.6\n",
      "2025-01-12 20:11:02.364300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 13232 MB memory:  -> device: 5, name: NVIDIA A16, pci bus id: 0000:cf:00.0, compute capability: 8.6\n",
      "2025-01-12 20:11:02.366894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 13232 MB memory:  -> device: 6, name: NVIDIA A16, pci bus id: 0000:d0:00.0, compute capability: 8.6\n",
      "2025-01-12 20:11:02.369667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 13232 MB memory:  -> device: 7, name: NVIDIA A16, pci bus id: 0000:d1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#loading mnist data from tensorflow\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "#mnist = tfds.load(name='mnist', split='train', as_supervised=True)\n",
    "# Returns both train and test split separately\n",
    "mnist_train, mnist_test = tfds.load('mnist', split=['train', 'test'], as_supervised=True)\n",
    "def preprocess_image(image, label):\n",
    "    image = image\n",
    "    #image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1] # i believe this is not in the original code\n",
    "    label = tf.one_hot(label, depth=10)  # One-hot encode the label\n",
    "    return image, label\n",
    "mnist_train = mnist_train.map(preprocess_image)\n",
    "mnist_test = mnist_test.map(preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psiAAeeymggr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions for layers\n",
    "def conv(x, weights, bias, strides = 1):\n",
    "    out = tf.nn.conv2d(x, weights, padding=\"SAME\", strides = [1, strides, strides, 1])\n",
    "    out = tf.nn.bias_add(out, bias)\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "\n",
    "def maxpooling(x, k = 2):\n",
    "    return tf.nn.max_pool(x, padding = \"SAME\", ksize = [1, k, k, 1], strides = [1, k, k, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktMBnG1ymggt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Hyperparameters & Setup\n",
    "# --------------------------------------------------------\n",
    "input_height = 28\n",
    "input_width = 28\n",
    "input_channels = 1\n",
    "\n",
    "# Base Model conv setup\n",
    "n_conv1 = 32\n",
    "n_conv2 = 64\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 1\n",
    "conv1_k = 5\n",
    "conv2_k = 5\n",
    "max_pool1_k = 2\n",
    "max_pool2_k = 2\n",
    "\n",
    "# Dense & Output\n",
    "n_hidden = 1024\n",
    "n_out = 10\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1. Base CNN\n",
    "# --------------------------------------------------------\n",
    "def cnn_base(inputs):\n",
    "    \"\"\"\n",
    "    The 'base' CNN model:\n",
    "      - Conv2D(32, kernel=5) + MaxPool(2)\n",
    "      - Conv2D(64, kernel=5) + MaxPool(2)\n",
    "      - Flatten\n",
    "      - Dense(1024) + Dropout(0.2)\n",
    "      - Dense(10, softmax)\n",
    "    \"\"\"\n",
    "    conv1 = layers.Conv2D(n_conv1,\n",
    "                          kernel_size=(conv1_k, conv1_k),\n",
    "                          strides=stride_conv1,\n",
    "                          padding=\"same\",\n",
    "                          activation=\"relu\")(inputs)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(max_pool1_k, max_pool1_k))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(n_conv2,\n",
    "                          kernel_size=(conv2_k, conv2_k),\n",
    "                          strides=stride_conv2,\n",
    "                          padding=\"same\",\n",
    "                          activation=\"relu\")(pool1)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(max_pool2_k, max_pool2_k))(conv2)\n",
    "\n",
    "    flatten = layers.Flatten()(pool2)\n",
    "    hidden = layers.Dense(n_hidden, activation=\"relu\")(flatten)\n",
    "\n",
    "    # A small dropout for regularization in the base model (can remove if desired)\n",
    "    dropout = layers.Dropout(0.2)(hidden)\n",
    "\n",
    "    outputs = layers.Dense(n_out, activation=\"softmax\")(dropout)\n",
    "    return outputs\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. Variation Model (similar complexity)\n",
    "# --------------------------------------------------------\n",
    "def cnn_variation(inputs):\n",
    "    \"\"\"\n",
    "    Variation model with similar complexity:\n",
    "      - 1st Conv has kernel_size=3\n",
    "      - 2nd Conv has kernel_size=5\n",
    "      - Dense(1024) + Dropout(0.2)\n",
    "      - Output(10)\n",
    "    \"\"\"\n",
    "    conv1 = layers.Conv2D(n_conv1,\n",
    "                          kernel_size=(3, 3),  # changed to 3x3\n",
    "                          strides=stride_conv1,\n",
    "                          padding=\"same\",\n",
    "                          activation=\"relu\")(inputs)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(max_pool1_k, max_pool1_k))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(n_conv2,\n",
    "                          kernel_size=(conv2_k, conv2_k),  # keep 5x5\n",
    "                          strides=stride_conv2,\n",
    "                          padding=\"same\",\n",
    "                          activation=\"relu\")(pool1)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(max_pool2_k, max_pool2_k))(conv2)\n",
    "\n",
    "    flatten = layers.Flatten()(pool2)\n",
    "    hidden = layers.Dense(n_hidden, activation=\"relu\")(flatten)\n",
    "    dropout = layers.Dropout(0.2)(hidden)\n",
    "\n",
    "    outputs = layers.Dense(n_out, activation=\"softmax\")(dropout)\n",
    "    return outputs\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3. More Powerful Model\n",
    "# --------------------------------------------------------\n",
    "def cnn_powerful(inputs):\n",
    "    \"\"\"\n",
    "    More powerful model:\n",
    "      - 3 Conv layers (32, 64, 128) each with kernel=3\n",
    "      - BatchNormalization after each Conv\n",
    "      - 2 MaxPools total (or you can add a 3rd if desired)\n",
    "      - Larger Dense layer (2048) + Dropout(0.3)\n",
    "      - Output(10)\n",
    "    \"\"\"\n",
    "    # 1st Conv + Pool\n",
    "    conv1 = layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    bn1 = layers.BatchNormalization()(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(bn1)\n",
    "\n",
    "    # 2nd Conv + Pool\n",
    "    conv2 = layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "    bn2 = layers.BatchNormalization()(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(bn2)\n",
    "\n",
    "    # 3rd Conv (optionally add another pool if you want more downsampling)\n",
    "    conv3 = layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(pool2)\n",
    "    bn3 = layers.BatchNormalization()(conv3)\n",
    "    # pool3 = layers.MaxPooling2D(pool_size=(2, 2))(bn3) # uncomment if desired\n",
    "\n",
    "    flatten = layers.Flatten()(bn3)  # or pool3 if you used a 3rd pooling\n",
    "    hidden = layers.Dense(2048, activation=\"relu\")(flatten)\n",
    "    dropout = layers.Dropout(0.3)(hidden)\n",
    "\n",
    "    outputs = layers.Dense(n_out, activation=\"softmax\")(dropout)\n",
    "    return outputs\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4. Simpler Model\n",
    "# --------------------------------------------------------\n",
    "def cnn_simple(inputs):\n",
    "    \"\"\"\n",
    "    Simpler model:\n",
    "      - 1 Conv + Pool (32 filters)\n",
    "      - Flatten\n",
    "      - Dense(256)\n",
    "      - Output(10)\n",
    "    \"\"\"\n",
    "    conv1 = layers.Conv2D(32,\n",
    "                          kernel_size=(5, 5),\n",
    "                          strides=1,\n",
    "                          padding=\"same\",\n",
    "                          activation=\"relu\")(inputs)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    flatten = layers.Flatten()(pool1)\n",
    "    hidden = layers.Dense(256, activation=\"relu\")(flatten)\n",
    "    outputs = layers.Dense(n_out, activation=\"softmax\")(hidden)\n",
    "    return outputs\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Build Model function\n",
    "# --------------------------------------------------------\n",
    "def build_model(model_type=\"base\"):\n",
    "    \"\"\"\n",
    "    Build one of the four models: 'base', 'variation', 'powerful', or 'simple'.\n",
    "    Returns a tf.keras.Model.\n",
    "    \"\"\"\n",
    "    # Define the input layer\n",
    "    inputs = tf.keras.Input(shape=(input_height, input_width, input_channels))\n",
    "\n",
    "    # Build the selected model\n",
    "    if model_type == \"base\":\n",
    "        outputs = cnn_base(inputs)\n",
    "    elif model_type == \"variation\":\n",
    "        outputs = cnn_variation(inputs)\n",
    "    elif model_type == \"powerful\":\n",
    "        outputs = cnn_powerful(inputs)\n",
    "    elif model_type == \"simple\":\n",
    "        outputs = cnn_simple(inputs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}\")\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=f\"{model_type}_model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Nd0sB1XOmggv",
    "outputId": "e2817129-39a4-4317-aaf7-0043d729a2ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x = tf.keras.Input(shape=(input_pixels,))\n",
    "x = tf.keras.Input(shape=(input_height, input_width, input_channels))\n",
    "y = tf.keras.Input(shape=(n_out,))\n",
    "#pred is the model\n",
    "model=build_model(\"variation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKNqv-KZmgg0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) #changed from 0.01 to 0.001\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "train_data = mnist_train.batch(100)\n",
    "test_data = mnist_test.batch(100)\n",
    "# Get a single batch from the test data (a batch is a tuple of (image, label))\n",
    "#single_batch = next(iter(test_data))\n",
    "\n",
    "# single_batch is a tuple, where single_batch[0] contains the image and single_batch[1] contains the label\n",
    "#image, label = single_batch\n",
    "\n",
    "# You can print or inspect the first image and label from the batch\n",
    "#print(image[0].numpy())  # The first image in the batch\n",
    "#print(label[0].numpy())  # The label for the first image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 20:11:05.118957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8400\n",
      "2025-01-12 20:11:06.582127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 12s 11ms/step - loss: 0.8433 - accuracy: 0.9295\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 0.0639 - accuracy: 0.9799\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 0.0443 - accuracy: 0.9858\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 0.0366 - accuracy: 0.9883\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.0292 - accuracy: 0.9905\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.0315 - accuracy: 0.9899\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 0.0250 - accuracy: 0.9920\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 0.0266 - accuracy: 0.9919\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 0.0201 - accuracy: 0.9939\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 0.0219 - accuracy: 0.9936\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.0228 - accuracy: 0.9933\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 0.0220 - accuracy: 0.9937\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 0.0212 - accuracy: 0.9939\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 0.0219 - accuracy: 0.9939\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 0.0178 - accuracy: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe410059ac0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 12ms/step - loss: 0.0782 - accuracy: 0.9864\n",
      "Test accuracy: 0.9864000082015991\n",
      "summary: \n",
      "Model: \"variation_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              3212288   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,274,122\n",
      "Trainable params: 3,274,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data) #dropout is automatically set to 1.0 when calling model.evaluate\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "print(\"summary: \")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('CNNModel/variationCNN.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "7. CNN-MNIST_tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
