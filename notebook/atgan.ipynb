{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://__token__:****@gitlab.utsp.utwente.nl/api/v4/groups/271/-/packages/pypi/simple\n",
      "Requirement already satisfied: tensorflow==2.17.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (3.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.17.0) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow==2.17.0) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/s2587130/GAN/ATN-MNIST/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.0) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow==2.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j-u7YeIHADpz",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 02:38:06.444881: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-28 02:38:07.385593: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-28 02:38:07.574205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-28 02:38:07.931193: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-28 02:38:08.003950: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-28 02:38:08.697313: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-28 02:38:11.987830: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as K\n",
    "# import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"]= \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AiUKATSAx-l",
    "user_expressions": []
   },
   "source": [
    "### Saving and Loading Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEpZGARzA1bs",
    "user_expressions": []
   },
   "source": [
    "# AC-GAN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7qeHpDMA9TS",
    "user_expressions": []
   },
   "source": [
    "## AC-GAN Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "to3PUI0oA5mY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(K.Model):\n",
    "    \"\"\"\n",
    "    Generator component of AC-GAN for MNIST dataset\n",
    "\n",
    "    Args:\n",
    "    - latent_dim: Dimension of the latent space (generated as noise)\n",
    "    - n_classes: Number of classes(labels) in the dataset (default=10)\n",
    "\n",
    "    inherited from https://github.com/kochlisGit/Generative-Adversarial-Networks/blob/main/mnist-digits-acgan/digits-acgan.py\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim, n_classes=10):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Layers for Latent Inputs\n",
    "        self.dense1 = K.layers.Dense(units=7 * 7 * 256, use_bias=False)\n",
    "        self.bn1 = K.layers.BatchNormalization()\n",
    "        self.reshape1 = K.layers.Reshape(target_shape=[7, 7, 256])\n",
    "\n",
    "        # Layers for Label Inputs\n",
    "        self.embedding = K.layers.Embedding(input_dim=n_classes, output_dim=64)\n",
    "        self.dense2 = K.layers.Dense(units=7*7, use_bias=False)\n",
    "        self.bn2 = K.layers.BatchNormalization()\n",
    "        self.reshape2 = K.layers.Reshape(target_shape=(7, 7, 1))\n",
    "\n",
    "        # Layers for Merging Inputs (Combining Latent and Label Inputs)\n",
    "        self.conv1 = K.layers.Conv2DTranspose(filters=128, kernel_size=5, strides=1, padding='same', use_bias=False)\n",
    "        self.bn3 = K.layers.BatchNormalization()\n",
    "        self.dropout1 = K.layers.Dropout(rate=0.4)\n",
    "        self.conv2 = K.layers.Conv2DTranspose(filters=64, kernel_size=5, strides=2, padding='same', use_bias=False)\n",
    "        self.bn4 = K.layers.BatchNormalization()\n",
    "        self.dropout2 = K.layers.Dropout(rate=0.4)\n",
    "        self.conv3 = K.layers.Conv2DTranspose(filters=1, kernel_size=5, strides=2, padding='same', activation='tanh')\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        \"\"\"\n",
    "        Forward pass of the generator\n",
    "        - latent_inputs: Random noise from the latent space, using for generating images\n",
    "        - label_inputs: Labels for the images to be generated\n",
    "        - training: Boolean flag for whether training or testing\n",
    "        \"\"\"\n",
    "        latent_inputs, label_inputs = inputs\n",
    "\n",
    "        # Latent Inputs Layer (Dense Layer + BatchNorm + ReLU + Reshape)\n",
    "        x1 = self.dense1(latent_inputs)\n",
    "        x1 = self.bn1(x1, training=training)\n",
    "        x1 = K.layers.LeakyReLU()(x1)\n",
    "        x1 = self.reshape1(x1)\n",
    "\n",
    "        # Process label inputs\n",
    "        x2 = self.embedding(label_inputs)\n",
    "        x2 = self.dense2(x2)\n",
    "        x2 = self.bn2(x2, training=training)\n",
    "        x2 = K.layers.LeakyReLU()(x2)\n",
    "        x2 = self.reshape2(x2)\n",
    "\n",
    "        #\n",
    "        merged_inputs = K.layers.Concatenate()([x1, x2])\n",
    "        x = self.conv1(merged_inputs)\n",
    "        x = self.bn3(x, training=training)\n",
    "        x = K.layers.LeakyReLU()(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn4(x, training=training)\n",
    "        x = K.layers.LeakyReLU()(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsR-WKBJBABU",
    "user_expressions": []
   },
   "source": [
    "## AC-GAN Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3yrqKrnBCY2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(K.Model):\n",
    "    \"\"\"\n",
    "    Discriminator component of AC-GAN for MNIST dataset\n",
    "\n",
    "    Args:\n",
    "    - n_classes: Number of classes(labels) in the dataset (default=10) which predicted (discriminated) by the Discriminator\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Define layers\n",
    "        self.gaussian_noise = K.layers.GaussianNoise(stddev=0.2)\n",
    "        self.conv1 = K.layers.Conv2D(filters=64, kernel_size=5, strides=2, padding='same', use_bias=False)\n",
    "        self.bn1 = K.layers.BatchNormalization()\n",
    "        self.dropout1 = K.layers.Dropout(rate=0.4)\n",
    "        self.conv2 = K.layers.Conv2D(filters=128, kernel_size=5, strides=2, padding='same', use_bias=False)\n",
    "        self.bn2 = K.layers.BatchNormalization()\n",
    "        self.dropout2 = K.layers.Dropout(rate=0.4)\n",
    "\n",
    "        # flatten layer\n",
    "        self.flatten = K.layers.Flatten()\n",
    "\n",
    "        # Output layers: 2 Dense Layer for validity and label prediction\n",
    "        self.dense1 = K.layers.Dense(units=1, activation='sigmoid') # dense layer for validity the image\n",
    "        self.dense2 = K.layers.Dense(units=n_classes, activation='softmax') # dense layer for classifying the label\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        \"\"\"\n",
    "        Forward pass of the discriminator\n",
    "        Args:\n",
    "        - inputs: Input images to be discriminated. Passing the input (generated by the Generator) through the Discriminator\n",
    "        and output the validity and label prediction\n",
    "        - training: Boolean flag for whether training or testing\n",
    "\n",
    "        Returns:\n",
    "        - validity: Validity of the input image that the discriminator predicts\n",
    "        - label: Label of the input image that the discriminator predicts\n",
    "        \"\"\"\n",
    "        x = self.gaussian_noise(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = K.layers.LeakyReLU()(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = K.layers.LeakyReLU()(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # Output layers\n",
    "        validity = self.dense1(x)\n",
    "        label = self.dense2(x)\n",
    "\n",
    "        return validity, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHK84CyQBUxa",
    "user_expressions": []
   },
   "source": [
    "## AC-GAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "De4TvXlVBZAi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ACGAN(K.Model):\n",
    "    def __init__(self, generator, discriminator, latent_dim, n_classes=10):\n",
    "        super(ACGAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.generator_optimizer = K.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)\n",
    "        self.discriminator_optimizer = K.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "        # Define loss functions with label smoothing\n",
    "        self.binary_loss = K.losses.BinaryCrossentropy(label_smoothing=0.25) #\n",
    "        self.sparse_categorical_loss = K.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    def compile(self):\n",
    "        super(ACGAN, self).compile()\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        Forward pass of the ACGAN model.\n",
    "\n",
    "        Args:\n",
    "        - inputs: A list containing [latent_inputs, label_inputs] which refers to the random noise\n",
    "        - training: Boolean flag for whether training or testing\n",
    "\n",
    "        Returns:\n",
    "        - discriminated_validity: Validity of the input image that the discriminator predicts\n",
    "        - discriminated_label: Label of the input image that the discriminator predicts\n",
    "        \"\"\"\n",
    "        latent_inputs, label_inputs = inputs\n",
    "        generated_images = self.generator([latent_inputs, label_inputs], training=training)\n",
    "        discriminated_validity, discriminated_label = self.discriminator(generated_images, training=training)\n",
    "        return discriminated_validity, discriminated_label\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x_batch, y_batch = data\n",
    "        batch_size = tf.shape(x_batch)[0]\n",
    "\n",
    "        # Ground Truth labels\n",
    "        real_labels = tf.ones((batch_size, 1))\n",
    "        fake_labels = tf.zeros((batch_size, 1))\n",
    "        mixed_labels = tf.concat([real_labels, fake_labels], axis=0)\n",
    "\n",
    "        # Generate random noise and labels\n",
    "        random_latent_noise = tf.random.normal(shape=[batch_size, self.latent_dim]) #(32,128)\n",
    "        random_labels = np.random.randint(0, self.n_classes, size=[batch_size]) #(32,)\n",
    "\n",
    "        # Generate images\n",
    "        generated_images = self.generator([random_latent_noise, random_labels], training=True) #generator inputs: [(32,128), (32,)]\n",
    "\n",
    "        # ------------------------------- Train the Discriminator ---------------------------------------------\n",
    "        self.discriminator.trainable = True\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Get discriminator outputs for real images\n",
    "            real_validity, real_label = self.discriminator(x_batch, training=True)\n",
    "            # Get discriminator outputs for generated images\n",
    "            fake_validity, fake_label = self.discriminator(generated_images, training=True)\n",
    "\n",
    "            # Concatenate real and fake outputs\n",
    "            discriminated_validity = tf.concat([real_validity, fake_validity], axis=0)\n",
    "            discriminated_label = tf.concat([real_label, fake_label], axis=0)\n",
    "            mixed_generated_labels = tf.concat([y_batch, random_labels], axis=0)\n",
    "\n",
    "            discriminator_loss = [\n",
    "                self.binary_loss(mixed_labels, discriminated_validity), #\n",
    "                self.sparse_categorical_loss(mixed_generated_labels, discriminated_label)\n",
    "            ]\n",
    "            total_discriminator_loss = tf.reduce_mean(discriminator_loss[0]) + tf.reduce_mean(discriminator_loss[1])\n",
    "\n",
    "        gradients_D = tape.gradient(total_discriminator_loss, self.discriminator.trainable_variables)\n",
    "        if None in gradients_D:\n",
    "            raise ValueError(\"No gradients provided for some variables.\")\n",
    "        self.discriminator_optimizer.apply_gradients(zip(gradients_D, self.discriminator.trainable_variables))\n",
    "\n",
    "        # ------------------------------------- Train the Generator ---------------------------------------------\n",
    "        self.discriminator.trainable = False #disable the discriminator \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate images again to ensure they are within the tape context\n",
    "            generated_images = self.generator([random_latent_noise, random_labels], training=True)\n",
    "            discriminated_validity, discriminated_label = self.discriminator(generated_images, training=True)\n",
    "\n",
    "            generator_loss = [\n",
    "                self.binary_loss(real_labels, discriminated_validity), # label loss\n",
    "                self.sparse_categorical_loss(random_labels, discriminated_label) #\n",
    "            ]\n",
    "            total_generator_loss = tf.reduce_mean(generator_loss[0]) + tf.reduce_mean(generator_loss[1])\n",
    "\n",
    "        gradients_G = tape.gradient(total_generator_loss, self.generator.trainable_variables)\n",
    "        if None in gradients_G:\n",
    "            raise ValueError(\"No gradients provided for some variables.\")\n",
    "        self.generator_optimizer.apply_gradients(zip(gradients_G, self.generator.trainable_variables))\n",
    "\n",
    "        return {\n",
    "            \"d_loss\": total_discriminator_loss,\n",
    "            \"g_loss\": total_generator_loss\n",
    "        }\n",
    "\n",
    "    def generate_images(self, latent_space, labels):\n",
    "        \"\"\"\n",
    "        Generate images from the latent space and labels. Using Generator only.\n",
    "        Args:\n",
    "        - latent_space: Random noise from the latent space\n",
    "        - labels: Labels for the images to be generated\n",
    "        \"\"\"\n",
    "        return self.generator([latent_space, labels], training=False)\n",
    "    \n",
    "    def discriminate_images(self, images):\n",
    "        \"\"\"\n",
    "        Discriminate the images using the Discriminator.\n",
    "        Args:\n",
    "        - images: Images to be discriminated\n",
    "        \"\"\"\n",
    "        return self.discriminator(images, training=False)\n",
    "\n",
    "\n",
    "# ================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acgan(acgan, x_test, y_test, batch_size=32):\n",
    "    \"\"\"Evaluates the AC-GAN using the discriminator's auxiliary classifier.\"\"\"\n",
    "    _, aux_output = acgan.discriminator.predict(x_test, batch_size=batch_size)\n",
    "    predicted_labels = np.argmax(aux_output, axis=1)\n",
    "    accuracy = np.mean(predicted_labels == y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39ukblvkBm1H",
    "user_expressions": []
   },
   "source": [
    "## Training AC-GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiOLn-YKCNNU",
    "user_expressions": []
   },
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-sHChHcCRRH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# mnist_train, mnist_test = tfds.load('mnist', split=['train', 'test'],data_dir='~/tensorflow_datasets',  as_supervised=True)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = K.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "print(\"Training set:\", x_train.shape)\n",
    "print(\"Training label:\", y_train.shape)\n",
    "print(\"Test set:\", x_test.shape)\n",
    "print(\"Test label:\", y_test.shape)\n",
    "\n",
    "print(\"Normalizing and Reshaping the data...\")\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(np.float32)\n",
    "x_train = (x_train - 127.5) / 127.5\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype(np.float32)\n",
    "x_text = (x_test - 127.5) / 127.5\n",
    "\n",
    "print(\"Train label\", y_train.shape)\n",
    "print(\"Test label\", y_test.shape)\n",
    "\n",
    "print(\"Completed preprocessing the data!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQmcx5XSCWX-",
    "user_expressions": []
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExZoBeZoCZuz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "latent_dim = 128 #noise size\n",
    "n_classes = 10\n",
    "batch_size = 32\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sx7ZEUDcCb35",
    "user_expressions": []
   },
   "source": [
    "### Create Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DtGmFE_CDdC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the AC-GAN model\n",
    "generator = Generator(latent_dim, n_classes)\n",
    "discriminator = Discriminator(n_classes)\n",
    "\n",
    "# # # Dummy pass to ensure variables exist - TODO: REMOVE IF NOT NEEDED\n",
    "# _ = generator([tf.zeros((1, latent_dim)), tf.zeros((1,), dtype=tf.int32)], training=False)\n",
    "# _ = discriminator(tf.zeros((1, 28, 28, 1)), training=False)\n",
    "\n",
    "acgan = ACGAN(generator, discriminator, latent_dim, n_classes)\n",
    "\n",
    "acgan.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYGDT_GwCkGL",
    "user_expressions": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAk5c_F2CmG3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "# # Create the dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=x_train.shape[0])\n",
    "inputs = train_dataset.batch(batch_size=batch_size, drop_remainder=True).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "batches_per_epoch = x_train.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(inputs):\n",
    "        losses = acgan.train_step([x_batch, y_batch])\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            print(f\"Batch {i}/{batches_per_epoch}, Discriminator Loss: {losses['d_loss']}, Generator Loss: {losses['g_loss']}\")\n",
    "\n",
    "    print(f\"\\nEpoch ({epoch+1}/{epochs}): \\n Discriminator Loss: {losses['d_loss']}, Generator Loss: {losses['g_loss']}\\n\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "\n",
    "#===========================================================================     \n",
    "#                               Save the model\n",
    "print(\"Saving the model\")\n",
    "generator.save(\"models/ACGAN/generator-50epochs.keras\")\n",
    "discriminator.save(\"models/ACGAN/discriminator-50epochs.keras\")\n",
    "acgan.save(\"models/ACGAN/acgan-50epochs.keras\")\n",
    "#==========================================================================\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the AC-GAN\n",
    "accuracy = evaluate_acgan(acgan, x_test, y_test)\n",
    "print(f\"AC-GAN Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate and save some images from the AC-GAN ===========================================\n",
    "digits_per_class = 10\n",
    "random_noise = tf.random.normal(shape=[digits_per_class * n_classes, latent_dim]) # (100, 128)\n",
    "digit_targets = np.array([target for target in range(n_classes) for _ in range(digits_per_class)])\n",
    "generated_digits = generator.predict([random_noise, digit_targets])\n",
    "# generated_digits = ((generated_digits + 1) * 127.5).astype(np.uint8)\n",
    "\n",
    "save_dir = \"generated_digits_acgan\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "for i, digit in enumerate(generated_digits):\n",
    "    digit = np.reshape(digit * 127.5 + 127.5, (28, 28))\n",
    "    img = K.preprocessing.image.array_to_img(digit.reshape(28, 28, 1))\n",
    "    img.save(os.path.join(save_dir, f\"digit_{i}.png\"))\n",
    "# rows = 5\n",
    "# cols = 6\n",
    "# fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(10, 10))\n",
    "    #     ax = axes[i // cols, i % cols]\n",
    "    #     ax.imshow(digit, cmap='gray')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BDJneLRBiqD"
   },
   "source": [
    "# AT - GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGsKp9cyBt99"
   },
   "source": [
    "## Target Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NceTp0bIBmUF"
   },
   "outputs": [],
   "source": [
    "# AT-GAN MODELS: Extended from ACGAN for Adversarial Attack\n",
    "class TargetClassifier(K.Model):\n",
    "    \"\"\"\n",
    "    Target Classifier for the AT-GAN model.\n",
    "    This simply acts as the classifier (built from CNN-based) for the input images (MNIST) \n",
    "    of either real or generated images.\n",
    "    Using as the target for the attack.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(TargetClassifier, self).__init__()\n",
    "\n",
    "        # Classifier Layers\n",
    "        self.conv1 = K.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1))\n",
    "        self.pool1 = K.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = K.layers.Conv2D(64, (3, 3), activation='relu', padding='same')\n",
    "        self.pool2 = K.layers.MaxPooling2D((2, 2))\n",
    "\n",
    "        self.flatten = K.layers.Flatten()\n",
    "        self.fc1 = K.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = K.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwbPAPUdBr9I"
   },
   "source": [
    "## Attack Generator (`G_attack`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZP8IkqJB2aS"
   },
   "outputs": [],
   "source": [
    "class Attack_Generator(K.Model):\n",
    "    \"\"\"\n",
    "    G_attack simply a copy of AC-GAN Generator, and used for the adversarial attack.\n",
    "    Which transfering the output of the Generator to the Target Classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, generator):\n",
    "        super(Attack_Generator, self).__init__()\n",
    "        self.generator = generator\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        return self.generator(inputs, training=training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NxWKxJyB5GA"
   },
   "source": [
    "## AT-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJp7VSTxB7iD"
   },
   "outputs": [],
   "source": [
    "class ATGAN(K.Model):\n",
    "    def __init__(self, G_original, G_attack, f_target, noise_size, lambda_adv_at=2.0, lambda_dist=1.0):\n",
    "        self.G_original = G_original # Original Generator (G_original)\n",
    "        self.G_attack = G_attack # Adversarial Generator (G_attack)\n",
    "        self.f_target = f_target    # Target Classifier (f_target)\n",
    "\n",
    "        self.noise_size = noise_size # latent space size\n",
    "\n",
    "        self.lambda_adv_at = lambda_adv_at  # lambda for adversarial loss\n",
    "        self.lambda_dist = lambda_dist     # lambda for distance loss\n",
    "\n",
    "        self.optimizer_G_attack = K.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        self.sparse_categorical_loss = K.losses.SparseCategoricalCrossentropy()\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        return self.G_original(inputs, training=training)\n",
    "\n",
    "    def train_step_atgan(self, images, target_labels):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "\n",
    "        with tf.GradientTape() as g_attack_tape:\n",
    "            z = tf.random.normal([batch_size, self.noise_size])\n",
    "\n",
    "            # Generate adversarial images\n",
    "            adv_images = self.G_attack([z, target_labels], training=True)\n",
    "\n",
    "            # Target classifier's prediction on adversarial images\n",
    "            pred_adv = self.f_target(adv_images, training=False)\n",
    "\n",
    "            # 1. Adversarial Loss (La) ========================================================\n",
    "\n",
    "            la_loss = tf.reduce_mean(\n",
    "                self.sparse_categorical_loss(target_labels, pred_adv)\n",
    "            )\n",
    "\n",
    "            # 2. Distance Loss (Ld) ========================================================\n",
    "            # Add Gaussian noise\n",
    "            noise = tf.random.normal(shape=tf.shape(adv_images), mean=0.0, stddev=0.1)\n",
    "            adv_images_noisy = adv_images + noise\n",
    "\n",
    "            # Original images generated by G_original\n",
    "            orig_images = self.G_original([z, target_labels], training=False)\n",
    "\n",
    "            ld_loss = tf.reduce_mean(tf.square(orig_images - adv_images_noisy))\n",
    "\n",
    "            # Total adversarial loss for G_attack\n",
    "            g_attack_loss = self.lambda_adv_at * la_loss + self.lambda_dist * ld_loss\n",
    "\n",
    "        # Calculate G_attack gradients\n",
    "        g_attack_gradients = g_attack_tape.gradient(g_attack_loss, self.G_attack.trainable_variables)\n",
    "        self.optimizer_G_attack.apply_gradients(zip(g_attack_gradients, self.G_attack.trainable_variables))\n",
    "\n",
    "        return g_attack_loss, la_loss, ld_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_atgan(atgan, f_target, x_test, y_test, noise_size=128, n_classes=10, num_batches=100):\n",
    "    \"\"\"\n",
    "    Evaluates the AT-GAN by generating adversarial examples and testing the target classifier.\n",
    "\n",
    "    Args:\n",
    "        atgan: The trained ATGAN model.\n",
    "        f_target: The target classifier to be attacked.\n",
    "        x_test: Test dataset images.\n",
    "        y_test: True labels for the test dataset.\n",
    "        noise_size: The dimension of the random noise vector.\n",
    "        n_classes: Number of classes in the dataset.\n",
    "        num_batches: Number of batches to use for evaluation.\n",
    "    \"\"\"\n",
    "    target_classifier_fooled = 0\n",
    "\n",
    "    for _ in range(num_batches):\n",
    "        batch_indices = np.random.choice(len(x_test), size=batch_size)\n",
    "        x_batch = x_test[batch_indices]\n",
    "        y_batch = y_test[batch_indices]\n",
    "\n",
    "        z = tf.random.normal([batch_size, noise_size])\n",
    "        \n",
    "        # Generate target labels that are different from the true labels\n",
    "        target_labels = (y_batch + np.random.randint(1, n_classes, size=batch_size)) % n_classes\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_examples = atgan.G_attack([z, target_labels], training=False)\n",
    "\n",
    "        # Classify adversarial examples with the target classifier\n",
    "        predictions = f_target.predict(adv_examples)\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "        # Count how many times the target classifier was fooled\n",
    "        target_classifier_fooled += np.sum(predicted_labels == target_labels)\n",
    "\n",
    "    # Calculate the success rate of the attack\n",
    "    fooling_rate = (target_classifier_fooled / (num_batches * batch_size)) * 100\n",
    "    print(f\"AT-GAN Attack Success Rate: {fooling_rate:.2f}%\")\n",
    "    return fooling_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train AT-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "epochs_atgan = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train target classifier\n",
    "# f_target = TargetClassifier(num_classes=10)\n",
    "f_target = TargetClassifier(num_classes=10)\n",
    "f_target.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "f_target.fit(x_train, y_train, epochs=5, batch_size=batch_size, validation_data=(x_test, y_test))\n",
    "\n",
    "# Create G_attack and AT-GAN\n",
    "attack_generator = Attack_Generator(generator)\n",
    "\n",
    "# # Dummy pass to ensure variables exist\n",
    "    # _ = attack_generator([tf.zeros((1, latent_dim)), tf.zeros((1,), dtype=tf.int32)], training=False)\n",
    "\n",
    "atgan = ATGAN(\n",
    "    G_original=generator, \n",
    "    G_attack=attack_generator, \n",
    "    f_target=f_target, \n",
    "    noise_size=latent_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train AT-GAN\n",
    "for epoch in range(epochs_atgan):\n",
    "    print('\\nTraining AT-GAN on epoch', epoch + 1)\n",
    "    for i, (x_batch, _) in enumerate(inputs):\n",
    "        target_labels = np.random.randint(0, n_classes, size=[batch_size])\n",
    "        g_attack_loss, la_loss, ld_loss = atgan.train_step_atgan(x_batch, target_labels)\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            print(f'Batch {i}, G_attack Loss: {g_attack_loss}, La Loss: {la_loss}, Ld Loss: {ld_loss}')\n",
    "\n",
    "    print(f'\\nEpoch ({epoch + 1}/{epochs_atgan}):\\n G_attack Loss: {g_attack_loss}, La Loss: {la_loss}, Ld Loss: {ld_loss}\\n')\n",
    "\n",
    "\n",
    "print('Training AT-GAN complete!')\n",
    "\n",
    "# Save the AT-GAN model\n",
    "print(\"Saving the AT-GAN model, G_attack, and Target Classifier\")\n",
    "try:\n",
    "    atgan.save(\"models/ATGAN/atgan-50epochs.keras\")\n",
    "    attack_generator.save(\"models/ATGAN/g_attack-50epochs.keras\")\n",
    "    f_target.save(\"models/ATGAN/target_classifier-50epochs.keras\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving the AT-GAN model: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate AT-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_success_rate = evaluate_atgan(atgan, f_target, x_test, y_test)\n",
    "print(f\"AT-GAN Attack Success Rate: {attack_success_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_adv_examples(atgan, f_target, noise_size, n_classes, num_examples_per_class, save_dir):\n",
    "    \"\"\"Generates and saves adversarial examples using the AT-GAN.\"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for target_class in range(n_classes):\n",
    "        z = tf.random.normal([num_examples_per_class, noise_size])\n",
    "        target_labels = np.full((num_examples_per_class,), target_class)\n",
    "\n",
    "        adv_examples = atgan.G_attack([z, target_labels], training=False)\n",
    "        # adv_examples = ((adv_examples + 1) * 127.5).numpy().astype(np.uint8)  # Rescale to 0-255\n",
    "\n",
    "        for i, adv_example in enumerate(adv_examples):\n",
    "            adv_example = np.reshape(adv_example * 127.5 + 127.5, (28, 28))\n",
    "            img = K.preprocessing.image.array_to_img(adv_example.reshape(28, 28, 1))\n",
    "\n",
    "            img.save(os.path.join(save_dir, f\"x_adv_{target_class}_{i}.png\"))\n",
    "\n",
    "# Example usage: Generate and save adversarial examples\n",
    "num_examples_per_class = 10\n",
    "save_dir = \"adversarial_examples\"\n",
    "generate_and_save_adv_examples(atgan, f_target, latent_dim, n_classes, num_examples_per_class, save_dir)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "B7qeHpDMA9TS",
    "VGsKp9cyBt99",
    "lwbPAPUdBr9I",
    "3NxWKxJyB5GA"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
