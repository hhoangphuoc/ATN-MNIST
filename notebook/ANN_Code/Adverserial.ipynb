{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!~/new_python_3_11_env/bin/python3 -m pip install tensorflow-datasets\n",
    "#!~/new_python_3_11_env/bin/python3 -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCL6UCvWmggf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 17:18:19.606562: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-15 17:18:19.710376: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-15 17:18:20.588608: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-15 17:18:20.588671: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-15 17:18:20.588676: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers, models\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 17:18:25.350475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13598 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5\n",
      "2025-01-15 17:18:25.352903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13598 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:d8:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Load original model\n",
    "original_model = tf.keras.models.load_model('CNNModel/BaseCNN.keras')  # Replace with your model file\n",
    "original_model.trainable = False  # Freeze weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @ layers with 2 deconvolution layers\n",
    "def build_atn(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        # First convolutional layers to capture features\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),  # Downsample (14, 14, 64)\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),  # Downsample (7, 7, 128)\n",
    "\n",
    "        # Fully connected layer to integrate features\n",
    "        layers.Flatten(),  # Flatten to shape (7 * 7 * 128 = 6272)\n",
    "        layers.Dense(6272, activation='relu'),  # Match the reshape target\n",
    "\n",
    "        # Deconvolution layers to reconstruct adversarial examples\n",
    "        layers.Reshape((7, 7, 128)),  # Reshape for deconvolution\n",
    "        layers.Conv2DTranspose(128, (3, 3), activation='relu', strides=2, padding='same'),  # (14, 14, 128)\n",
    "        layers.Conv2DTranspose(64, (3, 3), activation='relu', strides=2, padding='same'),  # (28, 28, 64)\n",
    "        \n",
    "        layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same'),  # Output layer (28, 28, 1)\n",
    "        layers.Lambda(lambda x: x * 255)  # Scale to [0, 255]\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Build the ATN\n",
    "input_shape = (28, 28, 1)  # MNIST dataset shape\n",
    "atn = build_atn(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef build_atn(input_shape):\\n    model = tf.keras.Sequential([\\n        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\\n        layers.MaxPooling2D((2, 2)),\\n        layers.Conv2D(64, (3, 3), activation='relu'),\\n        layers.Flatten(),\\n        layers.Dense(128, activation='relu'),\\n        layers.Dense(np.prod(input_shape), activation='sigmoid'),  # Use sigmoid for range [0, 1]\\n        layers.Reshape(input_shape),\\n        layers.Lambda(lambda x: x * 255)  # Scale to [0, 255]\\n    ])\\n    return model\\n\\n\\ninput_shape = (28, 28, 1)  # Assuming MNIST dataset\\natn = build_atn(input_shape)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define ATN 2 Layers only convulution\n",
    "'''\n",
    "def build_atn(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(np.prod(input_shape), activation='sigmoid'),  # Use sigmoid for range [0, 1]\n",
    "        layers.Reshape(input_shape),\n",
    "        layers.Lambda(lambda x: x * 255)  # Scale to [0, 255]\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = (28, 28, 1)  # Assuming MNIST dataset\n",
    "atn = build_atn(input_shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define input loss and output loss function\n",
    "def input_loss(x, x_prime):\n",
    "    return tf.reduce_mean(tf.square(tf.cast(x, tf.float32) - x_prime))  # Cast x to float32  # L2 loss\n",
    "\n",
    "def output_loss(y_pred, y_target):\n",
    "    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_target, y_pred)) # crossentropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the models\n",
    "input_img = tf.keras.Input(shape=input_shape)\n",
    "x_prime = atn(input_img)\n",
    "y_pred = original_model(x_prime)\n",
    "\n",
    "combined_model = tf.keras.Model(inputs=input_img, outputs=[x_prime, y_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_second_highest_target(y_pred_original):\n",
    "    # Sort predictions to find the highest and second-highest indices\n",
    "    top_2_indices = tf.argsort(y_pred_original, direction='DESCENDING', axis=1)[:, :2]\n",
    "    second_highest_indices = top_2_indices[:, 1]\n",
    "\n",
    "    # Create one-hot encoding for the second-highest class\n",
    "    y_target = tf.one_hot(second_highest_indices, depth=y_pred_original.shape[1])\n",
    "    return y_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training procedure\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "beta = 0.01  # Weight for input-space loss\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y_original):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Generate adversarial examples\n",
    "        x_prime = atn(x)\n",
    "\n",
    "        # Get predictions for original and adversarial inputs\n",
    "        y_pred_original = original_model(x, training=False)\n",
    "        y_pred = original_model(x_prime, training=False)\n",
    "\n",
    "        # Compute the second-highest target dynamically\n",
    "        y_target = get_second_highest_target(y_pred_original)\n",
    "\n",
    "        # Compute input loss and output loss separately\n",
    "        l_x = input_loss(x, x_prime)\n",
    "        l_y = output_loss(y_pred, y_target)\n",
    "\n",
    "        # Compute the combined loss\n",
    "        loss = beta * l_x + l_y\n",
    "\n",
    "    # Compute and apply gradients\n",
    "    gradients = tape.gradient(loss, atn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, atn.trainable_variables))\n",
    "\n",
    "    # Return total loss, input loss, and output loss\n",
    "    return loss, l_x, l_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "_dUJNbrZmggi",
    "outputId": "3802d63c-a895-4db8-ab3f-6d73da0341ea",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded without normalization.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST datasetatn\n",
    "mnist_train, mnist_test = tfds.load('mnist', split=['train', 'test'], as_supervised=True)\n",
    "\n",
    "# Function to create adversarial target labels\n",
    "#def create_adversarial_target(label):\n",
    "#    # Example: Shift each label by 1 (cyclic mapping)\n",
    "#    return (label + 1) % 10\n",
    "\n",
    "# Preprocessing function for training the ATN\n",
    "def preprocess_image_atn(image, label):\n",
    "    # Do NOT normalize the images; keep them in the range [0, 255]\n",
    "    image = tf.cast(image, tf.float32)  # Ensure float32 for compatibility with loss functions\n",
    "    label_one_hot = tf.one_hot(label, depth=10)  # One-hot encode the original label\n",
    "    \n",
    "    # Return only the raw image and the original label\n",
    "    return image, label_one_hot\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "mnist_train_atn = mnist_train.map(preprocess_image_atn)\n",
    "mnist_test_atn = mnist_test.map(preprocess_image_atn)\n",
    "\n",
    "# Batch and prefetch the dataset\n",
    "batch_size = 32\n",
    "mnist_train_atn = mnist_train_atn.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "mnist_test_atn = mnist_test_atn.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Dataset loaded without normalization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/1875 [00:00<?, ?it/s]2025-01-15 17:18:28.288367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8400\n",
      "Epoch 1/50: 100%|██████████| 1875/1875 [00:36<00:00, 51.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       10.5847     8.6173      1.9674      36.38     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 1875/1875 [00:32<00:00, 58.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       5.7605      4.2348      1.5256      32.11     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50:   8%|▊         | 152/1875 [00:02<00:30, 56.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_original_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(mnist_train_atn, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     22\u001b[0m     loss, l_x, l_y \u001b[38;5;241m=\u001b[39m train_step(x_batch, y_original_batch)  \u001b[38;5;66;03m# Get all losses\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     epoch_input_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m l_x\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m*\u001b[39mbeta\n\u001b[1;32m     25\u001b[0m     epoch_output_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m l_y\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1155\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1121\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1120\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "#beta = 0.1  # Weight for the input-space loss\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "print(f\"{'Epoch':<8}{'Total Loss':<12}{'Scaled Input Loss':<12}{'Output Loss':<12}{'Time (s)':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    epoch_loss = 0\n",
    "    epoch_input_loss = 0\n",
    "    epoch_output_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    # Add progress bar for batches\n",
    "    for x_batch, y_original_batch in tqdm(mnist_train_atn, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "        loss, l_x, l_y = train_step(x_batch, y_original_batch)  # Get all losses\n",
    "        epoch_loss += loss.numpy()\n",
    "        epoch_input_loss += l_x.numpy()*beta\n",
    "        epoch_output_loss += l_y.numpy()\n",
    "        batch_count += 1\n",
    "\n",
    "    # Compute average losses for the epoch\n",
    "    avg_loss = epoch_loss / batch_count\n",
    "    avg_input_loss = epoch_input_loss / batch_count\n",
    "    avg_output_loss = epoch_output_loss / batch_count\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"{epoch + 1:<8}{avg_loss:<12.4f}{avg_input_loss:<12.4f}{avg_output_loss:<12.4f}{elapsed_time:<10.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the ATN in the newer `.keras` format for future compatibility\n",
    "\n",
    "# Define model naming function\n",
    "def generate_model_name(base_name, beta, epochs, structure):\n",
    "    # Format the model name with hyperparameters\n",
    "    return f\"{base_name}_beta-{beta}_epochs-{epochs}_{structure}.keras\"\n",
    "\n",
    "# Specify model details\n",
    "#base_name = \"adversarial_transformation_network\"\n",
    "\n",
    "#structure = \"conv2d_transpose\"  # Example structure (descriptive)\n",
    "\n",
    "# Generate the model name\n",
    "#model_name = generate_model_name(base_name, beta, epochs, structure)\n",
    "model_name='ATNBase_atn2.keras'\n",
    "# Save the ATN with the generated name\n",
    "atn.save(model_name)\n",
    "print(f\"ATN saved successfully as {model_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Model\n",
    "\n",
    "\n",
    "#loaded_atn_model = tf.keras.models.load_model('ATN_model/ATNPure.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to evaluate and compare results\n",
    "def evaluate_atn(original_model, atn, dataset):\n",
    "    for x_batch, y_original_batch in dataset.take(1):  # Take one batch (two elements per batch in the dataset)\n",
    "        # Generate transformed images\n",
    "        x_transformed = atn.predict(x_batch)\n",
    "\n",
    "        # Get predictions for the original and transformed images\n",
    "        y_pred_original = tf.argmax(original_model.predict(x_batch), axis=1)\n",
    "        y_pred_transformed = tf.argmax(original_model.predict(x_transformed), axis=1)\n",
    "\n",
    "        # Get true labels\n",
    "        y_true = tf.argmax(y_original_batch, axis=1)\n",
    "\n",
    "        # Print results for comparison\n",
    "        print(\"True Labels:\", y_true.numpy())\n",
    "        print(\"Original Predictions:\", y_pred_original.numpy())\n",
    "        print(\"Transformed Predictions:\", y_pred_transformed.numpy())\n",
    "\n",
    "        # Display images\n",
    "        display_images(x_batch, x_transformed, y_true, y_pred_original, y_pred_transformed, original_model.predict(x_batch))\n",
    "        break  # Only evaluate one batch for now\n",
    "\n",
    "# Function to display images\n",
    "def display_images(original_images, transformed_images, y_true, y_pred_original, y_pred_transformed, original_pred):\n",
    "    num_images = min(10, len(original_images))  # Display up to 10 images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Original image\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(tf.squeeze(original_images[i]), cmap='gray')  # Remove channel for grayscale display\n",
    "        plt.title(f\"Label: {y_true[i].numpy()}, \\n Pred: {y_pred_original[i].numpy()}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Transformed image\n",
    "        second_highest_target = get_second_highest_target(original_pred[i: i + 1])[0]  # Compute target dynamically\n",
    "        second_highest_class = tf.argmax(second_highest_target).numpy()\n",
    "\n",
    "        plt.subplot(2, num_images, i + 1 + num_images)\n",
    "        plt.imshow(tf.squeeze(transformed_images[i]), cmap='gray')\n",
    "        plt.title(f\"Target: {second_highest_class}, \\n Pred: {y_pred_transformed[i].numpy()}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Evaluate the ATN on the test dataset\n",
    "evaluate_atn(original_model, atn, mnist_test_atn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(model, dataset, atn=None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x_batch, y_original_batch in dataset:  # Only unpack two elements\n",
    "        if atn:\n",
    "            # Transform images using ATN\n",
    "            x_batch = atn.predict(x_batch, verbose=0)  # Suppress verbose output\n",
    "        # Get predictions from the model\n",
    "        y_pred = tf.argmax(model.predict(x_batch, verbose=0), axis=1)\n",
    "        y_true = tf.argmax(y_original_batch, axis=1)  # True labels\n",
    "        # Count correct predictions\n",
    "        correct += tf.reduce_sum(tf.cast(y_pred == y_true, tf.float32)).numpy()\n",
    "        total += x_batch.shape[0]  # Batch size\n",
    "    \n",
    "    return correct / total  # Calculate accuracy\n",
    "\n",
    "\n",
    "# Original accuracy\n",
    "original_accuracy = calculate_accuracy(original_model, mnist_test_atn, atn=None)\n",
    "print(f\"Accuracy on original images: {original_accuracy:.4f}\")\n",
    "\n",
    "# Transformed accuracy\n",
    "transformed_accuracy = calculate_accuracy(original_model, mnist_test_atn, atn=atn)\n",
    "print(f\"Accuracy on transformed images: {transformed_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "7. CNN-MNIST_tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
