{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!~/new_python_3_11_env/bin/python3 -m pip install tensorflow-datasets\n",
    "#!~/new_python_3_11_env/bin/python3 -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCL6UCvWmggf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 13:54:45.118134: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-13 13:54:45.303865: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-13 13:54:46.160607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-13 13:54:46.160685: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-13 13:54:46.160690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers, models\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 13:54:54.200766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12533 MB memory:  -> device: 0, name: NVIDIA A16, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2025-01-13 13:54:54.204294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9417 MB memory:  -> device: 1, name: NVIDIA A16, pci bus id: 0000:1c:00.0, compute capability: 8.6\n",
      "2025-01-13 13:54:54.206287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 12769 MB memory:  -> device: 2, name: NVIDIA A16, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2025-01-13 13:54:54.208241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 12769 MB memory:  -> device: 3, name: NVIDIA A16, pci bus id: 0000:1e:00.0, compute capability: 8.6\n",
      "2025-01-13 13:54:54.210334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 12769 MB memory:  -> device: 4, name: NVIDIA A16, pci bus id: 0000:ce:00.0, compute capability: 8.6\n",
      "2025-01-13 13:54:54.212487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 12769 MB memory:  -> device: 5, name: NVIDIA A16, pci bus id: 0000:cf:00.0, compute capability: 8.6\n",
      "2025-01-13 13:54:54.215143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 12769 MB memory:  -> device: 6, name: NVIDIA A16, pci bus id: 0000:d0:00.0, compute capability: 8.6\n",
      "2025-01-13 13:54:54.217264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 12769 MB memory:  -> device: 7, name: NVIDIA A16, pci bus id: 0000:d1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Load original model\n",
    "original_model_base = tf.keras.models.load_model('CNNModel/BaseCNN.keras')  # Replace with your model file\n",
    "original_model_base.trainable = False  # Freeze weights\n",
    "original_model_strong = tf.keras.models.load_model('CNNModel/BaseCNNkernal3.keras')  # Replace with your model file\n",
    "original_model_strong.trainable = False  # Freeze weights\n",
    "original_model_simple = tf.keras.models.load_model('CNNModel/BaseCNNkernal7.keras')  # Replace with your model file\n",
    "\n",
    "\n",
    "original_model_simple.trainabl=False\n",
    "\n",
    "original_model = tf.keras.models.load_model('CNNModel/BaseCNN.keras')  # Replace with your model file\n",
    "original_model.trainable = False  # Freeze weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @ layers with 2 deconvolution layers\n",
    "def build_atn(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        # First convolutional layers to capture features\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),  # Downsample (14, 14, 64)\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),  # Downsample (7, 7, 128)\n",
    "\n",
    "        # Fully connected layer to integrate features\n",
    "        layers.Flatten(),  # Flatten to shape (7 * 7 * 128 = 6272)\n",
    "        layers.Dense(6272, activation='relu'),  # Match the reshape target\n",
    "\n",
    "        # Deconvolution layers to reconstruct adversarial examples\n",
    "        layers.Reshape((7, 7, 128)),  # Reshape for deconvolution\n",
    "        layers.Conv2DTranspose(128, (3, 3), activation='relu', strides=2, padding='same'),  # (14, 14, 128)\n",
    "        layers.Conv2DTranspose(64, (3, 3), activation='relu', strides=2, padding='same'),  # (28, 28, 64)\n",
    "        \n",
    "        layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same'),  # Output layer (28, 28, 1)\n",
    "        layers.Lambda(lambda x: x * 255)  # Scale to [0, 255]\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Build the ATN\n",
    "input_shape = (28, 28, 1)  # MNIST dataset shape\n",
    "atn = build_atn(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ATN 2 Layers only convulution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define input loss and output loss function\n",
    "def input_loss(x, x_prime):\n",
    "    return tf.reduce_mean(tf.square(tf.cast(x, tf.float32) - x_prime))  # Cast x to float32  # L2 loss\n",
    "\n",
    "def output_loss(y_pred, y_target):\n",
    "    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_target, y_pred)) # crossentropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_second_highest_target(y_pred_original):\n",
    "    # Sort predictions to find the highest and second-highest indices\n",
    "    top_2_indices = tf.argsort(y_pred_original, direction='DESCENDING', axis=1)[:, :2]\n",
    "    second_highest_indices = top_2_indices[:, 1]\n",
    "\n",
    "    # Create one-hot encoding for the second-highest class\n",
    "    y_target = tf.one_hot(second_highest_indices, depth=y_pred_original.shape[1])\n",
    "    return y_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomApply(tf.keras.layers.Layer):\n",
    "    def __init__(self, layer, p=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layer = layer\n",
    "        self.p = p\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        if not training:\n",
    "            return x\n",
    "        return tf.cond(\n",
    "            tf.random.uniform(()) < self.p,\n",
    "            lambda: self.layer(x, training=training),\n",
    "            lambda: x\n",
    "        )\n",
    "\n",
    "# A simple pipeline: horizontal flip, random rotation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomApply(layers.RandomRotation(0.2), p=0.5),\n",
    "    RandomApply(layers.RandomZoom(0.1,fill_mode='nearest'), p=0.5),\n",
    "])\n",
    "augmentation_with_p = RandomApply(data_augmentation, p=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training procedure\n",
    "boundaries = [250000]  # Steps at which learning rate changes\n",
    "values = [0.001, 0.0001]  # Corresponding learning rates\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=boundaries,\n",
    "    values=values\n",
    ")\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, clipnorm=1.0)\n",
    "beta = 0.01  # Weight for input-space loss\n",
    "@tf.function\n",
    "def train_step(x, y_original):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Generate adversarial examples\n",
    "        x_prime = atn(x)\n",
    "        x_primeT = augmentation_with_p(x_prime, training=True)\n",
    "        # Get predictions for original and adversarial inputs\n",
    "        y_pred = (\n",
    "            original_model_base(x_primeT, training=False), axis=-1)+\n",
    "            original_model_strong(x_primeT, training=False)+\n",
    "            original_model_simple(x_primeT, training=False)\n",
    "        )\n",
    "        y_pred_original =(original_model_base(x, training=False) + tf.nn.softmax(original_model_strong(x, training=False)\n",
    "                          + tf.nn.softmax(original_model_simple(x, training=False))\n",
    "           \n",
    "\n",
    "        # Normalize the predictions\n",
    "        y_pred =y_pred/3\n",
    "        y_pred_original = y_pred_original/3\n",
    "\n",
    "        # Compute the second-highest target dynamically\n",
    "        y_target = get_second_highest_target(y_pred_original)\n",
    "\n",
    "        # Compute input loss and output loss separately\n",
    "        l_x = input_loss(x, x_prime)\n",
    "        l_y = output_loss(y_pred, y_target)\n",
    "\n",
    "        # Compute the combined loss\n",
    "        loss = beta * l_x + l_y\n",
    "\n",
    "    # Compute and apply gradients\n",
    "    gradients = tape.gradient(loss, atn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, atn.trainable_variables))\n",
    "\n",
    "    # Return total loss, input loss, and output loss\n",
    "    return loss, l_x, l_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "_dUJNbrZmggi",
    "outputId": "3802d63c-a895-4db8-ab3f-6d73da0341ea",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded without normalization.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST datasetatn\n",
    "mnist_train, mnist_test = tfds.load('mnist', split=['train', 'test'], as_supervised=True)\n",
    "\n",
    "# Function to create adversarial target labels\n",
    "#def create_adversarial_target(label):\n",
    "#    # Example: Shift each label by 1 (cyclic mapping)\n",
    "#    return (label + 1) % 10\n",
    "\n",
    "# Preprocessing function for training the ATN\n",
    "def preprocess_image_atn(image, label):\n",
    "    # Do NOT normalize the images; keep them in the range [0, 255]\n",
    "    image = tf.cast(image, tf.float32)  # Ensure float32 for compatibility with loss functions\n",
    "    label_one_hot = tf.one_hot(label, depth=10)  # One-hot encode the original label\n",
    "    \n",
    "    # Return only the raw image and the original label\n",
    "    return image, label_one_hot\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "mnist_train_atn = mnist_train.map(preprocess_image_atn)\n",
    "mnist_test_atn = mnist_test.map(preprocess_image_atn)\n",
    "\n",
    "# Batch and prefetch the dataset\n",
    "batch_size = 32\n",
    "mnist_train_atn = mnist_train_atn.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "mnist_test_atn = mnist_test_atn.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Dataset loaded without normalization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   Total Loss  Scaled Input LossOutput Loss Time (s)  \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "2025-01-13 13:55:02.820233: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8400\n",
      "2025-01-13 13:55:04.855086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Epoch 1/100: 100%|██████████| 1875/1875 [00:39<00:00, 48.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       12.2003     9.8543      2.3460      39.05     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 1875/1875 [00:28<00:00, 64.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       6.2841      3.9316      2.3525      29.00     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 1875/1875 [00:28<00:00, 64.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3       5.7079      3.3550      2.3528      28.93     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 1875/1875 [00:28<00:00, 66.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4       5.4108      3.0578      2.3530      28.37     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 1875/1875 [00:28<00:00, 65.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       5.2155      2.8625      2.3530      28.58     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 1875/1875 [00:28<00:00, 64.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6       5.1095      2.7564      2.3531      28.99     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7       5.0154      2.6623      2.3531      29.41     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8       4.9549      2.6018      2.3531      29.49     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 1875/1875 [00:28<00:00, 65.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9       4.8917      2.5385      2.3531      28.80     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10      4.8256      2.4724      2.3532      29.65     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11      4.7688      2.4156      2.3532      29.31     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 1875/1875 [00:28<00:00, 65.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12      4.7132      2.3600      2.3532      28.63     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 1875/1875 [00:29<00:00, 64.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13      4.6396      2.2864      2.3532      29.23     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 1875/1875 [00:26<00:00, 70.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14      4.5597      2.2064      2.3533      26.79     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 1875/1875 [00:27<00:00, 69.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15      4.5073      2.1540      2.3533      27.10     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 1875/1875 [00:28<00:00, 66.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16      4.4558      2.1026      2.3533      28.18     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17      4.4077      2.0543      2.3533      29.52     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 1875/1875 [00:29<00:00, 64.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18      4.3294      1.9761      2.3533      29.18     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 1875/1875 [00:28<00:00, 65.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19      4.2885      1.9351      2.3533      28.77     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20      4.2599      1.9066      2.3533      29.56     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21      4.2358      1.8825      2.3533      29.34     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22      4.1992      1.8459      2.3533      29.46     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 1875/1875 [00:29<00:00, 62.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23      4.1536      1.8002      2.3533      29.97     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24      4.1226      1.7693      2.3533      29.75     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 1875/1875 [00:28<00:00, 65.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25      4.1065      1.7532      2.3533      28.62     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 1875/1875 [00:26<00:00, 69.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26      4.0820      1.7287      2.3533      26.89     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27      4.0709      1.7176      2.3533      29.51     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28      4.0454      1.6921      2.3533      29.61     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 1875/1875 [00:29<00:00, 62.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29      4.0226      1.6692      2.3533      29.96     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 1875/1875 [00:29<00:00, 62.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30      4.0149      1.6616      2.3533      29.82     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 1875/1875 [00:29<00:00, 62.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31      4.0110      1.6577      2.3533      29.97     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32      3.9997      1.6464      2.3533      29.65     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33      3.9791      1.6258      2.3533      29.48     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 1875/1875 [00:29<00:00, 62.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34      3.9851      1.6317      2.3534      29.99     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 1875/1875 [00:29<00:00, 62.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35      3.9881      1.6347      2.3533      29.81     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36      3.9744      1.6211      2.3533      29.48     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 1875/1875 [00:28<00:00, 65.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37      3.9501      1.5968      2.3533      28.42     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 1875/1875 [00:27<00:00, 67.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38      3.9456      1.5923      2.3533      27.70     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 1875/1875 [00:29<00:00, 62.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39      3.9494      1.5961      2.3533      29.77     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40      3.9396      1.5863      2.3533      29.71     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 1875/1875 [00:30<00:00, 62.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41      3.9308      1.5775      2.3533      30.09     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42      3.9443      1.5910      2.3533      29.75     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43      3.9371      1.5838      2.3533      29.67     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 1875/1875 [00:29<00:00, 62.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44      3.9130      1.5597      2.3533      29.82     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45      3.9141      1.5608      2.3533      29.67     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46      3.9123      1.5589      2.3533      29.61     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 1875/1875 [00:29<00:00, 62.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47      3.9268      1.5735      2.3533      29.80     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 1875/1875 [00:30<00:00, 62.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48      3.9223      1.5690      2.3533      30.07     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 1875/1875 [00:27<00:00, 68.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49      3.9048      1.5515      2.3533      27.55     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50      3.9000      1.5467      2.3533      29.50     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51      3.9050      1.5517      2.3533      29.65     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 1875/1875 [00:29<00:00, 64.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52      3.8990      1.5457      2.3533      29.10     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 1875/1875 [00:29<00:00, 64.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53      3.9134      1.5601      2.3533      29.20     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 1875/1875 [00:30<00:00, 62.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54      3.8901      1.5368      2.3533      30.06     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55      3.8856      1.5323      2.3533      29.53     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 1875/1875 [00:29<00:00, 63.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56      3.8923      1.5390      2.3533      29.74     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100:  26%|██▋       | 493/1875 [00:07<00:20, 66.24it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Training loop\n",
    "epochs = 300\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "print(f\"{'Epoch':<8}{'Total Loss':<12}{'Scaled Input Loss':<12}{'Output Loss':<12}{'Time (s)':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    epoch_loss = 0\n",
    "    epoch_input_loss = 0\n",
    "    epoch_output_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    # Add progress bar for batches\n",
    "    for x_batch, y_original_batch in tqdm(mnist_train_atn, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "        loss, l_x, l_y = train_step(x_batch, y_original_batch)  # Get all losses\n",
    "        epoch_loss += loss.numpy()\n",
    "        epoch_input_loss += l_x.numpy()*beta\n",
    "        epoch_output_loss += l_y.numpy()\n",
    "        batch_count += 1\n",
    "\n",
    "    # Compute average losses for the epoch\n",
    "    avg_loss = epoch_loss / batch_count\n",
    "    avg_input_loss = epoch_input_loss / batch_count\n",
    "    avg_output_loss = epoch_output_loss / batch_count\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"{epoch + 1:<8}{avg_loss:<12.4f}{avg_input_loss:<12.4f}{avg_output_loss:<12.4f}{elapsed_time:<10.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the ATN in the newer `.keras` format for future compatibility\n",
    "\n",
    "# Define model naming function\n",
    "def generate_model_name(base_name, beta, epochs, structure):\n",
    "    # Format the model name with hyperparameters\n",
    "    return f\"{base_name}_beta-{beta}_epochs-{epochs}_{structure}.keras\"\n",
    "\n",
    "# Specify model details\n",
    "#base_name = \"adversarial_transformation_network\"\n",
    "\n",
    "#structure = \"conv2d_transpose\"  # Example structure (descriptive)\n",
    "\n",
    "# Generate the model name\n",
    "#model_name = generate_model_name(base_name, beta, epochs, structure)\n",
    "model_name='ATN_model/ATNMultSCALE_ensemble_ATN2.keras'\n",
    "# Save the ATN with the generated name\n",
    "atn.save(model_name)\n",
    "print(f\"ATN saved successfully as {model_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Model\n",
    "\n",
    "\n",
    "#loaded_atn_model = tf.keras.models.load_model('ATN_model/ATNPure.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to evaluate and compare results\n",
    "def evaluate_atn(original_model, atn, dataset):\n",
    "    for x_batch, y_original_batch in dataset.take(1):  # Take one batch (two elements per batch in the dataset)\n",
    "        # Generate transformed images\n",
    "        x_transformed = atn.predict(x_batch)\n",
    "\n",
    "        # Get predictions for the original and transformed images\n",
    "        y_pred_original = tf.argmax(original_model.predict(x_batch), axis=1)\n",
    "        y_pred_transformed = tf.argmax(original_model.predict(x_transformed), axis=1)\n",
    "\n",
    "        # Get true labels\n",
    "        y_true = tf.argmax(y_original_batch, axis=1)\n",
    "\n",
    "        # Print results for comparison\n",
    "        print(\"True Labels:\", y_true.numpy())\n",
    "        print(\"Original Predictions:\", y_pred_original.numpy())\n",
    "        print(\"Transformed Predictions:\", y_pred_transformed.numpy())\n",
    "\n",
    "        # Display images\n",
    "        display_images(x_batch, x_transformed, y_true, y_pred_original, y_pred_transformed, original_model.predict(x_batch))\n",
    "        break  # Only evaluate one batch for now\n",
    "\n",
    "# Function to display images\n",
    "def display_images(original_images, transformed_images, y_true, y_pred_original, y_pred_transformed, original_pred):\n",
    "    num_images = min(10, len(original_images))  # Display up to 10 images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Original image\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(tf.squeeze(original_images[i]), cmap='gray')  # Remove channel for grayscale display\n",
    "        plt.title(f\"Label: {y_true[i].numpy()}, \\n Pred: {y_pred_original[i].numpy()}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Transformed image\n",
    "        second_highest_target = get_second_highest_target(original_pred[i: i + 1])[0]  # Compute target dynamically\n",
    "        second_highest_class = tf.argmax(second_highest_target).numpy()\n",
    "\n",
    "        plt.subplot(2, num_images, i + 1 + num_images)\n",
    "        plt.imshow(tf.squeeze(transformed_images[i]), cmap='gray')\n",
    "        plt.title(f\"Target: {second_highest_class}, \\n Pred: {y_pred_transformed[i].numpy()}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Evaluate the ATN on the test dataset\n",
    "evaluate_atn(original_model, atn, mnist_test_atn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(model, dataset, atn=None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x_batch, y_original_batch in dataset:  # Only unpack two elements\n",
    "        if atn:\n",
    "            # Transform images using ATN\n",
    "            x_batch = atn.predict(x_batch, verbose=0)  # Suppress verbose output\n",
    "        # Get predictions from the model\n",
    "        y_pred = tf.argmax(model.predict(x_batch, verbose=0), axis=1)\n",
    "        y_true = tf.argmax(y_original_batch, axis=1)  # True labels\n",
    "        # Count correct predictions\n",
    "        correct += tf.reduce_sum(tf.cast(y_pred == y_true, tf.float32)).numpy()\n",
    "        total += x_batch.shape[0]  # Batch size\n",
    "    \n",
    "    return correct / total  # Calculate accuracy\n",
    "\n",
    "\n",
    "# Original accuracy\n",
    "original_accuracy = calculate_accuracy(original_model, mnist_test_atn, atn=None)\n",
    "print(f\"Accuracy on original images: {original_accuracy:.4f}\")\n",
    "\n",
    "# Transformed accuracy\n",
    "transformed_accuracy = calculate_accuracy(original_model, mnist_test_atn, atn=atn)\n",
    "print(f\"Accuracy on transformed images: {transformed_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "7. CNN-MNIST_tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
