import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import tensorflow as tf
import keras as K
import numpy as np

from modules.acgan import Generator, Discriminator
from modules.target import TargetClassifier

# =================================================================================================
#                AT-GAN
# =================================================================================================

@K.saving.register_keras_serializable()
class Attack_Generator(K.Model):
    """
    G_attack simply a copy of AC-GAN Generator, and used for the adversarial attack.
    Which transfering the output of the Generator to the Target Classifier.
    """

    def __init__(self, generator, name="attack_generator", **kwargs):
        super(Attack_Generator, self).__init__(name=name, **kwargs)
        self.generator = generator


    # def build(self, input_shape):
    #     super(Attack_Generator, self).build(input_shape)
    #     self.generator.build(input_shape)

    def call(self, inputs, training=False):
        return self.generator(inputs, training=training)
    
    def get_config(self):
        config = super(Attack_Generator, self).get_config()
        config.update({
            "generator": self.generator
        })
        return config

    @classmethod
    def from_config(cls, config):
        # # Assuming generator is a class that can be instantiated directly
        generator_config = config.pop('generator')
        # generator = Generator.from_config(generator_config)
        generator = Generator(latent_dim=128, n_classes=10)

        return cls(generator=generator, **config)

# =================================================================================================


@K.saving.register_keras_serializable()
class ATGAN(K.Model):
    def __init__(self, G_original, G_attack, f_target, noise_size, lambda_adv_at=2.0, lambda_dist=1.0, name="atgan", **kwargs):
        super(ATGAN, self).__init__(name=name, **kwargs)
        self.G_original = G_original # Original Generator (G_original)
        self.G_attack = G_attack # Adversarial Generator (G_attack)
        self.f_target = f_target    # Target Classifier (f_target)

        self.noise_size = noise_size # latent space size

        self.lambda_adv_at = lambda_adv_at  # lambda for adversarial loss
        self.lambda_dist = lambda_dist     # lambda for distance loss

        self.optimizer_G_attack = K.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
        self.sparse_categorical_loss = K.losses.SparseCategoricalCrossentropy()

    def call(self, inputs, training=False):
        return self.G_original(inputs, training=training)

    # @tf.function
    def train_step_atgan(self, images, target_labels):
        batch_size = tf.shape(images)[0]

        with tf.GradientTape() as g_attack_tape:
            z = tf.random.normal([batch_size, self.noise_size])

            # Generate adversarial images
            adv_images = self.G_attack([z, target_labels], training=True)

            # Target classifier's prediction on adversarial images
            pred_adv = self.f_target(adv_images, training=False)

            # 1. Adversarial Loss (La) ========================================================

            la_loss = tf.reduce_mean(
                self.sparse_categorical_loss(target_labels, pred_adv)
            )

            # 2. Distance Loss (Ld) ========================================================
            # Add Gaussian noise
            noise = tf.random.normal(shape=tf.shape(adv_images), mean=0.0, stddev=0.1)
            adv_images_noisy = adv_images + noise

            # Original images generated by G_original
            orig_images = self.G_original([z, target_labels], training=False)

            ld_loss = tf.reduce_mean(tf.square(orig_images - adv_images_noisy))

            # Total adversarial loss for G_attack
            g_attack_loss = self.lambda_adv_at * la_loss + self.lambda_dist * ld_loss

        # Calculate G_attack gradients
        g_attack_gradients = g_attack_tape.gradient(g_attack_loss, self.G_attack.trainable_variables)
        self.optimizer_G_attack.apply_gradients(zip(g_attack_gradients, self.G_attack.trainable_variables))

        return g_attack_loss, la_loss, ld_loss

    def get_config(self):
        config = super(ATGAN, self).get_config()
        config.update(
            {
                "G_original": K.utils.serialize_keras_object(self.G_original),
                "G_attack": K.utils.serialize_keras_object(self.G_attack),
                "f_target": K.utils.serialize_keras_object(self.f_target),
                "noise_size": self.noise_size,
                "lambda_adv_at": self.lambda_adv_at,
                "lambda_dist": self.lambda_dist,
            }
        )
        return config

    @classmethod
    def from_config(cls, config):
        # Deserialize the sub-models
        G_original = K.models.model_from_json(config["G_original"])
        G_attack = K.models.model_from_json(config["G_attack"])
        f_target = K.models.model_from_json(config["f_target"])

        # Remove the serialized sub-models from the config
        config.pop("G_original")
        config.pop("G_attack")
        config.pop("f_target")

        # Create and return an instance of ATGAN
        return cls(
            G_original=G_original,
            G_attack=G_attack,
            f_target=f_target,
            **config
        )

# ==========================================================================================================================

def evaluate_atgan(
        # atgan, 
        adversarial_generator, # atgan
        f_target, x_test, y_test, noise_size=128, n_classes=10, num_batches=100, batch_size=32):
    """
    Evaluates the AT-GAN by generating adversarial examples and testing the target classifier.

    Args:
        atgan: The trained GAN-based model. Which has been retrained with G_attack
        f_target: The target classifier to be attacked. This can be the target classifier
        that we trained, or the pretrained CNN-based model
        x_test: Test dataset images.
        y_test: True labels for the test dataset.
        noise_size: The dimension of the random noise vector.
        n_classes: Number of classes in the dataset.
        num_batches: Number of batches to use for evaluation.
    """
    target_classifier_fooled = 0

    for _ in range(num_batches):
        batch_indices = np.random.choice(len(x_test), size=batch_size)
        x_batch = x_test[batch_indices]
        y_batch = y_test[batch_indices]

        z = tf.random.normal([batch_size, noise_size])

        # Generate target labels that are different from the true labels
        target_labels = (y_batch + np.random.randint(1, n_classes, size=batch_size)) % n_classes

        # Generate adversarial examples
        # FIXME: IF ATGAN
        # adv_examples = atgan.G_attack([z, target_labels], training=False)
        adv_examples = adversarial_generator([z, target_labels], training=False)

        # Classify adversarial examples with the target classifier
        predictions = f_target.predict(adv_examples) #CNN model.predict
        predicted_labels = np.argmax(predictions, axis=1)

        # Count how many times the target classifier was fooled
        target_classifier_fooled += np.sum(predicted_labels == target_labels)

    # Calculate the success rate of the attack
    fooling_rate = (target_classifier_fooled / (num_batches * batch_size)) * 100
    print(f"AT-GAN Attack Success Rate: {fooling_rate:.2f}%")
    return fooling_rate

def generate_and_save_adv_examples(adversarial_generator, f_target, noise_size, n_classes, num_examples_per_class, save_dir):
    """Generates and saves adversarial examples using the AT-GAN."""
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    for target_class in range(n_classes):
        z = tf.random.normal([num_examples_per_class, noise_size])
        target_labels = np.full((num_examples_per_class,), target_class)

        adv_examples = adversarial_generator([z, target_labels], training=False) # Generate adversarial examples
        adv_examples = ((adv_examples + 1) * 127.5).numpy().astype(np.uint8)  # Rescale to 0-255

        for i, adv_example in enumerate(adv_examples):
            img = K.preprocessing.image.array_to_img(adv_example.reshape(28, 28, 1))
            img.save(os.path.join(save_dir, f"x_adv_{target_class}_{i}.png"))

#================================================================================================================

if __name__ == "__main__":
    # =================================================================================================================
    #                             Load and Preprocess Dataset (SIMILAR TO ALL OTHER MODELS)
    # =================================================================================================================
    (x_train, y_train), (x_test, y_test) = K.datasets.mnist.load_data(path="mnist.npz")

    print("Training set:", x_train.shape)
    print("Training label:", y_train.shape)
    print("Test set:", x_test.shape)
    print("Test label:", y_test.shape)

    print("Normalizing and Reshaping the data...")
    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(np.float32)
    x_train = (x_train - 127.5) / 127.5

    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype(np.float32)
    x_test = (x_test - 127.5) / 127.5  # Corrected variable name to x_test

    latent_dim = 128 #noise size
    n_classes = 10
    batch_size = 100
    epochs = 20
    epochs_atgan = 20

    # PREPROCESS DATASET
    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=x_train.shape[0])
    train_dataset = train_dataset.batch(batch_size=batch_size, drop_remainder=True).prefetch(buffer_size=tf.data.AUTOTUNE)

    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
    test_dataset = test_dataset.batch(batch_size=batch_size, drop_remainder=True).prefetch(
        buffer_size=tf.data.AUTOTUNE
    )
    print("Dataset loaded with normalization.")

    #================================================================================================================


    #-----------------------------------------------------------------------------------------------------------------
    #                              LOAD OTHER MODELS: TARGET CLASSIFIER, GENERATOR
    #-----------------------------------------------------------------------------------------------------------------
    # Load the target classifier
    target_classifier = K.models.load_model("../models/target/f_target.keras")
    target_classifier.trainable = False  # Freeze weights

    # Load the original generator
    g_original = K.models.load_model("../models/acgan/generator.keras")
    #-----------------------------------------------------------------------------------------------------
    #                                               AT-GAN
    #-----------------------------------------------------------------------------------------------------

    attack_generator = Attack_Generator(g_original)

    # # Dummy pass to ensure variables exist
    _ = attack_generator([tf.zeros((1, latent_dim)), tf.zeros((1,), dtype=tf.int32)], training=False)

    # Initialize the AT-GAN model
    atgan = ATGAN(
        G_original=g_original,
        G_attack=attack_generator,
        f_target=target_classifier,
        noise_size=latent_dim,
        lambda_adv_at=2.0, # lambda for adversarial loss
        lambda_dist=1.0 # lambda for distance loss
    )

    # Train AT-GAN
    for epoch in range(epochs_atgan):
        print('\nTraining AT-GAN on epoch', epoch + 1)
        for i, (x_batch, _) in enumerate(train_dataset):
            target_labels = np.random.randint(0, n_classes, size=[batch_size])
            g_attack_loss, la_loss, ld_loss = atgan.train_step_atgan(x_batch, target_labels)

            if i % 200 == 0:
                print(f'Batch {i}, G_attack Loss: {g_attack_loss}, La Loss: {la_loss}, Ld Loss: {ld_loss}')

        print(f'\nEpoch ({epoch + 1}/{epochs_atgan}):\n G_attack Loss: {g_attack_loss}, La Loss: {la_loss}, Ld Loss: {ld_loss}\n')

    print('Training AT-GAN complete!')

    # Save the AT-GAN model
    print("Saving the AT-GAN model, G_attack, and Target Classifier")
    try:
        attack_generator.save("../models/atgan/g_attack.keras")
        # attack_generator.save("models/atgan/g_attack.h5", save_format="h5")
    except Exception as e:
        print(f"Error saving the G_attack model: {e}")
    try:
        # Save
        atgan.save("../models/atgan/atgan.keras")
    except Exception as e:
        print(f"Error saving the AT-GAN model: {e}")

    #======================================================================================================================

    # # ==================================== LOAD MODEL ================================================
    # adversarial_generator = K.models.load_model("models/acgan/generator.keras")
    # # IF USE AT-GAN
    adversarial_generator = K.models.load_model("../models/atgan/g_attack.keras")
    target_classifier = K.models.load_model("../models/target/f_target.keras")
    # target_classifier.trainable = False  # Freeze weights


    #=================================================================================================


    #=====================================================================================================
    #                                   Evaluate the AT-GAN
    #=====================================================================================================
    attack_success_rate = evaluate_atgan(
        adversarial_generator, target_classifier, x_test, y_test)
    print(f"AT-GAN Attack Success Rate: {attack_success_rate:.2f}%")


    # Generate and save adversarial examples from the AT-GAN ===========================================
    num_examples_per_class = 3
    save_dir = "../data/atgan_images"
    generate_and_save_adv_examples(adversarial_generator, target_classifier, latent_dim, n_classes, num_examples_per_class, save_dir)
    print(f"Adversarial examples saved in {save_dir}")
